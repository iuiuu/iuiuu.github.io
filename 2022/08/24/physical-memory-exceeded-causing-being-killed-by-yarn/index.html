<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【Flink作业运行出错】beyond the 'PHYSICAL' memory limit. Killing container | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="keywords" content="Java,JVM,Spring,Spring Boot,Flink,Hadoop,Yarn,MySQL,Elasticsearch,Python,Kafka,Maven,Hbase,Kibana,Logstash,Tutorial,Technical Blogs,Data Structures,Algorithms,C,SQL,Data Science,Web Development,System Design,Interview Experience,Interview Preparation,Programming,Competitive Programming,Coding Contests,HTML,CSS,Computer Science,Programming Examples,Mathematics"><meta name="description" content="问题描述Flink 版本：1.13.6 部署模式：Flink On YARN Application Mode 当 Flink 作业在 YARN 上运行了几天之后，容器会因为物理内存使用超出物理内存限制而被杀死，并报如下错误： 1234567892022-08-12 12:36:04,168 WARN  akka.remote.ReliableDeliverySupervisor">
<meta property="og:type" content="article">
<meta property="og:title" content="【Flink作业运行出错】beyond the &#39;PHYSICAL&#39; memory limit. Killing container">
<meta property="og:url" content="http://linjiangxiong.com/2022/08/24/physical-memory-exceeded-causing-being-killed-by-yarn/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="问题描述Flink 版本：1.13.6 部署模式：Flink On YARN Application Mode 当 Flink 作业在 YARN 上运行了几天之后，容器会因为物理内存使用超出物理内存限制而被杀死，并报如下错误： 1234567892022-08-12 12:36:04,168 WARN  akka.remote.ReliableDeliverySupervisor">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/brand/flink-header-logo.svg">
<meta property="article:published_time" content="2022-08-23T17:35:01.000Z">
<meta property="article:modified_time" content="2022-08-25T15:43:14.162Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Flink">
<meta property="article:tag" content="备忘录">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/brand/flink-header-logo.svg"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2022/08/24/physical-memory-exceeded-causing-being-killed-by-yarn/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【Flink作业运行出错】beyond the \'PHYSICAL\' memory limit. Killing container',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-25 23:43:14'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">294</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">【Flink作业运行出错】beyond the 'PHYSICAL' memory limit. Killing container</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">【Flink作业运行出错】beyond the 'PHYSICAL' memory limit. Killing container</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-08-23T17:35:01.000Z" title="Created 2022-08-24 01:35:01">2022-08-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-08-25T15:43:14.162Z" title="Updated 2022-08-25 23:43:14">2022-08-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>Flink 版本：1.13.6</p>
<p>部署模式：Flink On YARN Application Mode</p>
<p>当 Flink 作业在 YARN 上运行了几天之后，容器会因为物理内存使用超出物理内存限制而被杀死，并报如下错误：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">2022-08-12 12:36:04,168 WARN  akka.remote.ReliableDeliverySupervisor                       [] - Association with remote system [akka.tcp://flink@flink-node-06:42477] has failed, address is now gated for [50] ms. Reason: [Association failed with [akka.tcp://flink@flink-node-06:42477]] Caused by: [java.net.ConnectException: Connection refused: flink-node-06/10.10.17.255:42477]</span><br><span class="line">2022-08-12 12:36:04,844 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e48_1655606936581_0285_01_000006 is terminated. Diagnostics: [2022-08-12 12:36:02.281]Container [pid=30100,containerID=container_e48_1655606936581_0285_01_000006] is running 65536B beyond the &#x27;PHYSICAL&#x27; memory limit. Current usage: 2.0 GB of 2 GB physical memory used; 3.8 GB of 8 GB virtual memory used. Killing container.</span><br><span class="line">Dump of the process-tree for container_e48_1655606936581_0285_01_000006 :</span><br><span class="line">	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE</span><br><span class="line">	|- 30100 30094 30100 30100 (bash) 0 0 118177792 369 /bin/bash -c /usr/java/jdk1.8.0_211-amd64/bin/java -Xmx697932173 -Xms697932173 -XX:MaxDirectMemorySize=300647712 -XX:MaxMetaspaceSize=268435456 -Dlog.file=/data/hadoop/yarn/log/application_1655606936581_0285/container_e48_1655606936581_0285_01_000006/taskmanager.log -Dlog4j.configuration=file:./log4j.properties -Dlog4j.configurationFile=file:./log4j.properties org.apache.flink.yarn.YarnTaskExecutorRunner -D taskmanager.memory.network.min=166429984b -D taskmanager.cpu.cores=1.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=214748368b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=166429984b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=665719939b -D taskmanager.memory.task.heap.size=563714445b -D taskmanager.numberOfTaskSlots=1 -D taskmanager.memory.jvm-overhead.max=214748368b --configDir . -Djobmanager.rpc.address=&#x27;flink-node-02&#x27; -Dpipeline.classpaths=&#x27;&#x27; -Dweb.port=&#x27;0&#x27; -Djobmanager.memory.off-heap.size=&#x27;134217728b&#x27; -Dweb.tmpdir=&#x27;/tmp/flink-web-5deb359d-87fb-49e3-bf4a-a9214dc667e8&#x27; -Djobmanager.rpc.port=&#x27;44848&#x27; -Drest.address=&#x27;flink-node-02&#x27; -Djobmanager.memory.jvm-overhead.max=&#x27;201326592b&#x27; -Djobmanager.memory.jvm-overhead.min=&#x27;201326592b&#x27; -Dtaskmanager.resource-id=&#x27;container_e48_1655606936581_0285_01_000006&#x27; -Dexecution.target=&#x27;embedded&#x27; -Dinternal.taskmanager.resource-id.metadata=&#x27;flink-node-06:45454&#x27; -Dpipeline.jars=&#x27;file:/data/hadoop/yarn/local/usercache/hadoop/appcache/application_1655606936581_0285/container_e48_1655606936581_0285_01_000001/flink_dw_prod.jar&#x27; -Djobmanager.memory.jvm-metaspace.size=&#x27;268435456b&#x27; -Djobmanager.memory.heap.size=&#x27;469762048b&#x27; 1&gt; /data/hadoop/yarn/log/application_1655606936581_0285/container_e48_1655606936581_0285_01_000006/taskmanager.out 2&gt; /data/hadoop/yarn/log/application_1655606936581_0285/container_e48_1655606936581_0285_01_000006/taskmanager.err </span><br><span class="line">	|- 30175 30100 30100 30100 (java) 1236701 120868 3967287296 523935 /usr/java/jdk1.8.0_211-amd64/bin/java -Xmx697932173 -Xms697932173 -XX:MaxDirectMemorySize=300647712 -XX:MaxMetaspaceSize=268435456 -Dlog.file=/data/hadoop/yarn/log/application_1655606936581_0285/container_e48_1655606936581_0285_01_000006/taskmanager.log -Dlog4j.configuration=file:./log4j.properties -Dlog4j.configurationFile=file:./log4j.properties org.apache.flink.yarn.YarnTaskExecutorRunner -D taskmanager.memory.network.min=166429984b -D taskmanager.cpu.cores=1.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=214748368b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=166429984b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=665719939b -D taskmanager.memory.task.heap.size=563714445b -D taskmanager.numberOfTaskSlots=1 -D taskmanager.memory.jvm-overhead.max=214748368b --configDir . -Djobmanager.rpc.address=flink-node-02 -Dpipeline.classpaths= -Dweb.port=0 -Djobmanager.memory.off-heap.size=134217728b -Dweb.tmpdir=/tmp/flink-web-5deb359d-87fb-49e3-bf4a-a9214dc667e8 -Djobmanager.rpc.port=44848 -Drest.address=flink-node-02 -Djobmanager.memory.jvm-overhead.max=201326592b -Djobmanager.memory.jvm-overhead.min=201326592b -Dtaskmanager.resource-id=container_e48_1655606936581_0285_01_000006 -Dexecution.target=embedded -Dinternal.taskmanager.resource-id.metadata=flink-node-06:45454 -Dpipeline.jars=file:/data/hadoop/yarn/local/usercache/hadoop/appcache/application_1655606936581_0285/container_e48_1655606936581_0285_01_000001/flink_dw_prod.jar -Djobmanager.memory.jvm-metaspace.size=268435456b -Djobmanager.memory.heap.size=469762048b </span><br><span class="line"></span><br><span class="line">[2022-08-12 12:36:02.322]Container killed on request. Exit code is 143</span><br><span class="line">[2022-08-12 12:36:02.330]Container exited with a non-zero exit code 143.</span><br></pre></td></tr></table></figure>

<p>该作业在 Flink History Server 的详情界面的 Exceptions 标签下可以看到以下错误信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.apache.flink.runtime.io.network.netty.exception.RemoteTransportException: Connection unexpectedly closed by remote task manager &#x27;flink-node-06/10.10.18.25:16407&#x27;. This might indicate that the remote task manager was lost.</span><br></pre></td></tr></table></figure>

<p>在 Exceptions 下的错误信息可以看到 Flink 集群的一个 TaskManager 节点连接不上。从 YARN 错误日志可以看出，该 TaskManager 节点连接不上，是因为 TaskManager 内存使用大小超出了容器的限制而被杀死。</p>
<p>既然问题是 TaskManager 内存不足引起的，那么尝试通过增加 TaskManager 内存的方式来解决该问题，将 TaskManager 内存由原来的 2048m 增加到 3072m，再次运行该作业，但它仍然每隔几天就报同样的错误。</p>
<p>调大 TaskManager 运行内存后，作业的启动参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Djobmanager.memory.process.size=1024m -Dtaskmanager.memory.process.size=3072m</span><br></pre></td></tr></table></figure>

<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>YARN 日志的异常信息表明 TaskManager 消耗的内存比预期的要多。虽然 TaskManager 因为内存超限运行被 YARN 杀死，并不代表这里有内存泄漏。</p>
<p>我们知道，Flink 集群上的 TaskManager 本质上还是一个 Java 程序。Java 程序可能会消耗各种类型的内存：堆、直接、本地、元空间。在所有这些类型的内存当中，除了本地内存外，Flink 通过 JVM 参数设置了明确的上限，因此如果进程尝试使用超过限制的内存，则会抛出 <code>OutOfMemoryError</code>。但在 YARN 日志中并没有 OOM 相关的异常信息，唯一的可能是 Flink 使用了比计划更多的本地内存。</p>
<p>所以，这里再尝试增加 JVM Overhead 内存占比，让 Flink 在容器中预留更多的本地内存。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>通过设置 <code>taskmanager.memory.jvm-overhead.fraction</code> 参数来增加 JVM Overhead 内存占比，以达到在容器中预留更多的本地内存。该参数的默认值为 0.1，修改为 0.2 后，重新启动该作业，后续观察该作业的运行情况，没有再出现因为内存超限运行被 YARN 杀死的异常。</p>
<p>修改后作业的启动参数如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Djobmanager.memory.process.size=1024m -Dtaskmanager.memory.process.size=3072m -Dtaskmanager.memory.jvm-overhead.fraction=0.2</span><br></pre></td></tr></table></figure>

<p>（END）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2022/08/24/physical-memory-exceeded-causing-being-killed-by-yarn/">http://linjiangxiong.com/2022/08/24/physical-memory-exceeded-causing-being-killed-by-yarn/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a><a class="post-meta__tags" href="/tags/%E5%A4%87%E5%BF%98%E5%BD%95/">备忘录</a></div><div class="post-share"><div class="social-share" data-image="/image/brand/flink-header-logo.svg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2022/08/24/lateral-view-explode-in-presto/" title="在Presto中实现Hive LATERAL VIEW EXPLODE"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">在Presto中实现Hive LATERAL VIEW EXPLODE</div></div><div class="info-2"><div class="info-item-1">我是 Presto 新手，我们公司数据仓库中有一张表（表名：dwd_user_country），记录了用户到访过的国家与地区。这里为简化问题描述，将该表结构抽象为两个字段：user_id 和 countries，其中 countries 字段的值采用英文逗号连接用户到访过的国家与地区。 表数据如下表所示：    user_id countries    26841018 中国,马来西亚,美国,瑞士,泰国,冰岛   现在，我需要从该表中统计每个国家或地区的到访人数，在 Hive 语法中，我可以使用 LATERAL VIEW EXPLODE 将该表的数据转成以下格式，再按 country 字段做 GROUP BY 统计。如果现在是使用 Presto 该怎么做呢？    user_id country    26841018 中国   26841018 马来西亚   26841018 美国   26841018 瑞士   26841018 泰国   26841018 冰岛    Hive 查询 首先使用 split 函数将 countries 字段分割成数组，再使用 lateral...</div></div></div></a><a class="pagination-related" href="/2022/08/23/how-to-compress-and-decompress-files-or-folders-in-linux/" title="【Linux常用命令】tar压缩和解压文件或文件夹"><img class="cover" src="/image/brand/centos.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">【Linux常用命令】tar压缩和解压文件或文件夹</div></div><div class="info-2"><div class="info-item-1">压缩文件1tar -zcvf ljx.tar.gz ./linjiangxiong/  该命令表示压缩当前文件夹下的文件夹 linjiangxiong，压缩后的文件名为 ljx.tar.gz 。 如果需要压缩多个文件，只需要在命令末尾追加需要压缩的文件即可，如： 1tar -zcvf ljx.tar.gz ./linjiangxiong/ ./ljx/  解压文件1tar -xzvf ljx.tar.gz  该命令表示把后缀为 .tar.gz 的文件解压到当前文件夹下。 如果需要将文件解压缩到其他目录，则使用命令： 1tar -xzvf ljx.tar.gz -C /opt/ljx  该命令表示把后缀为 .tar.gz 的文件解压到 /opt/ljx 目录下。 （END） </div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/" title="Lightweight Asynchronous Snapshots for Distributed Dataflows"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="info-item-2">Lightweight Asynchronous Snapshots for Distributed Dataflows</div></div><div class="info-2"><div class="info-item-1">Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}@sics.se3Data Artisans GmbH - {stephan, kostas}@data-artisans.com AbstractDistributed stateful stream processing enables the deployment and execution of large scale continuous omputations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this...</div></div></div></a><a class="pagination-related" href="/2023/09/09/apache-flink-features/" title="Apache Flink的核心特性"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="info-item-2">Apache Flink的核心特性</div></div><div class="info-2"><div class="info-item-1">在大数据和实时数据处理的时代，Apache Flink 以其卓越的性能和灵活性成为了业界的明星。本文将深入探讨这款框架的核心特性，以帮助我们更好地理解其在大数据分析和实时数据处理方面的优势和应用场景。 批流一体Flink 采用了统一的流处理架构，可以用相同的编程模型和运行时系统支持有界数据的批处理和无界数据的实时流处理。这种设计理念使 Flink 在企业技术选型中具有重要意义： 首先，Flink 消除了批处理和流处理之间的鸿沟，企业无需再采用多套框架分别实现两者。这简化了架构设计，降低了系统复杂度。其次，统一的编程模型可以重用批处理和流处理的代码逻辑，提高开发效率。开发人员无需学习多种编程模型，大大减少了学习和开发成本。最后，单一的运行时系统简化了运维工作，无须部署和维护多套框架，可以节省大量运维成本。 也就是说，Flink 的统一流处理架构为企业提供了一个高效、灵活、易于使用的大数据处理解决方案。如果 Flink 能够满足业务需求，就无须用两种甚至多种框架分别实现批处理和流处理，这大大降低了架构设计、开发、运维的复杂度，可以节省大量人力成本。这是 Flink...</div></div></div></a><a class="pagination-related" href="/2023/03/10/lsm-tree-intro/" title="Flink Table Store文件存储结构——LSM树"><img class="cover" src="/image/2023/20230310.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="info-item-2">Flink Table Store文件存储结构——LSM树</div></div><div class="info-2"><div class="info-item-1">本文简要介绍了 Flink Table Store 底层文件存储的数据结构——LSM 树的相关概念。  LSM 树，亦称日志结构合并树，英文为 log-structured merge-tree。  Sorted Runs如下图所示，LSM 树将文件组织成若干个 Sorted Run，一个 Sorted Run 由一个或多个数据文件组成，每个数据文件只会隶属一个 Sorted Run。数据文件中的记录按主键排序，在一个 Sorted Run 中，数据文件的主键范围不会有重叠的情况。但在不同的 Sorted Run 中主键范围有可能会重叠，甚至是包含相同的主键。  当查询 LSM 树时，必须先合并所有的 Sorted Run，根据用户指定的合并引擎和每条记录的时间戳合并具有相同主键的所有记录。而新的记录在写到 LSM 树之前会先缓存在内存中，当内存缓冲区满时，内存中的所有记录会先进行排序，然后再刷到磁盘上，此时就创建了一个新的 Sorted Run。 Compaction随着越来越多的记录写入 LSM 树，Sorted Run 的数量也会越来越多。因为查询 LSM...</div></div></div></a><a class="pagination-related" href="/2023/02/16/flink-sql-table-api-configuration-dependency/" title="Flink依赖配置：Table API &amp; SQL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-16</div><div class="info-item-2">Flink依赖配置：Table API &amp; SQL</div></div><div class="info-2"><div class="info-item-1">我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，所以这里我使用到的 Table API 连接器有 Kafka Connector，Canal Connector。 pom.xml...</div></div></div></a><a class="pagination-related" href="/2023/09/10/apache-flink-history-server/" title="了解Flink中的History Server：记录和展示作业历史信息的重要工具"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="info-item-2">了解Flink中的History Server：记录和展示作业历史信息的重要工具</div></div><div class="info-2"><div class="info-item-1">Flink 中的 History Server 是一个非常有用的组件，可以在相应的 Flink 集群关闭之后查询已完成作业的统计信息。并且，它还提供了一个 REST API，可接受 HTTP 请求并以 JSON 数据作为响应。本文将详细介绍 Flink History Server 的工作原理和主要功能。 一、History Server工作原理Apache Flink 自带了一个 HistoryServer 进程，它是一个独立的 Web 服务器。HistoryServer 不参与 Flink 作业执行，仅用于展示作业的历史信息。它的工作原理如下：  JobManager 会将已完成的作业的信息以存档文件的形式写入 HDFS 或者其他持久存储中。 HistoryServer 读取这些存档文件，并提供 Web 界面展示其信息内容。 用户通过 HistoryServer 的 Web UI 查看作业记录和运行数据。  每个作业完成后，JobManager 会把该作业的信息打包成一个个 JSON 格式的归档文件，包括作业配置信息、作业执行过程中的 Checkpoint...</div></div></div></a><a class="pagination-related" href="/2023/09/01/apache-flink-use-cases/" title="探究Apache Flink支持的三种流处理场景"><img class="cover" src="/image/2023/20230901-image1.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-01</div><div class="info-item-2">探究Apache Flink支持的三种流处理场景</div></div><div class="info-2"><div class="info-item-1">Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实际上，Flink 能够扩展到数千个内核和 TB 级的应用状态，提供高吞吐量和低延迟，并为世界上一些要求最苛刻的流处理应用提供支持。 本文将介绍 Flink...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">294</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">问题分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">3.</span> <span class="toc-text">解决方案</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/18/bulk-deleting-keys-in-redis-using-wildcards/" title="Bulk Deleting Keys in Redis Using Wildcards">Bulk Deleting Keys in Redis Using Wildcards</a><time datetime="2024-09-18T15:42:56.000Z" title="Created 2024-09-18 23:42:56">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"><img src="/image/redis-src/2024091101.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"/></a><div class="content"><a class="title" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing">Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing</a><time datetime="2024-09-10T22:28:03.000Z" title="Created 2024-09-11 06:28:03">2024-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"><img src="/image/redis-src/24091002.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"/></a><div class="content"><a class="title" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation">Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation</a><time datetime="2024-09-09T17:13:55.000Z" title="Created 2024-09-10 01:13:55">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/06/why-does-redis-use-the-sds-structure-for-strings-instead-of-char/" title="Why Does Redis Use the SDS Structure for Strings Instead of char*?">Why Does Redis Use the SDS Structure for Strings Instead of char*?</a><time datetime="2024-09-05T16:01:26.000Z" title="Created 2024-09-06 00:01:26">2024-09-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/05/how-to-delete-data-in-elasticsearch-single-multiple-clear-and-all/" title="How to Delete Data in Elasticsearch: Single, Multiple, Clear, and All">How to Delete Data in Elasticsearch: Single, Multiple, Clear, and All</a><time datetime="2024-09-04T16:02:38.000Z" title="Created 2024-09-05 00:02:38">2024-09-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>