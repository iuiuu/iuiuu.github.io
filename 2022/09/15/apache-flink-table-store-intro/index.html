<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Apache Flink Table Store——流批一体存储 | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="keywords" content="Java,JVM,Spring,Spring Boot,Flink,Hadoop,Yarn,MySQL,Elasticsearch,Python,Kafka,Maven,Hbase,Kibana,Logstash,Tutorial,Technical Blogs,Data Structures,Algorithms,C,SQL,Data Science,Web Development,System Design,Interview Experience,Interview Preparation,Programming,Competitive Programming,Coding Contests,HTML,CSS,Computer Science,Programming Examples,Mathematics"><meta name="description" content="Flink Table Store 面向更新场景的 OLAP 应用。作为流批统一存储，在 Flink 中为流式处理和批处理构建动态表，支持实时流式更新&#x2F;删除变更日志摄取、实时流消费和高性能数据查询。当大量更新数据（如 MySQL 的 binlog 日志）写入 Flink Table Store 后，Flink Table Store 后台会根据主键来合并数据，默认保留最新变更后的数据。Flink">
<meta property="og:type" content="article">
<meta property="og:title" content="Apache Flink Table Store——流批一体存储">
<meta property="og:url" content="http://linjiangxiong.com/2022/09/15/apache-flink-table-store-intro/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="Flink Table Store 面向更新场景的 OLAP 应用。作为流批统一存储，在 Flink 中为流式处理和批处理构建动态表，支持实时流式更新&#x2F;删除变更日志摄取、实时流消费和高性能数据查询。当大量更新数据（如 MySQL 的 binlog 日志）写入 Flink Table Store 后，Flink Table Store 后台会根据主键来合并数据，默认保留最新变更后的数据。Flink">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/2022/20220915234511-flink-table-store-architecture.png">
<meta property="article:published_time" content="2022-09-15T15:08:21.000Z">
<meta property="article:modified_time" content="2022-09-15T15:52:37.343Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Flink">
<meta property="article:tag" content="Flink Table Store">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/2022/20220915234511-flink-table-store-architecture.png"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2022/09/15/apache-flink-table-store-intro/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Apache Flink Table Store——流批一体存储',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-15 23:52:37'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">Apache Flink Table Store——流批一体存储</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Apache Flink Table Store——流批一体存储</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-09-15T15:08:21.000Z" title="Created 2022-09-15 23:08:21">2022-09-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-09-15T15:52:37.343Z" title="Updated 2022-09-15 23:52:37">2022-09-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><blockquote>
<p>Flink Table Store 面向更新场景的 OLAP 应用。作为流批统一存储，在 Flink 中为流式处理和批处理构建动态表，支持实时流式更新/删除变更日志摄取、实时流消费和高性能数据查询。当大量更新数据（如 MySQL 的 binlog 日志）写入 Flink Table Store 后，Flink Table Store 后台会根据主键来合并数据，默认保留最新变更后的数据。<br><strong>Flink Table Store 目前仍处于 beta 状态，正在快速发展，不建议直接在生产环境中使用。</strong></p>
</blockquote>
<h2 id="出现背景"><a href="#出现背景" class="headerlink" title="出现背景"></a>出现背景</h2><p>在过去的几年里，得益于众多的贡献者和用户，Apache Flink 已经成为最好的分布式计算引擎之一，尤其是在大规模有状态流处理方面。然而，当试图深入了解实时数据时，仍然面临着一些挑战。在这些挑战中，一个突出的问题是缺乏满足所有计算模式的存储。</p>
<p>到目前为止，为了不同目的部署几个存储系统来使用 Flink 是很常见的。一个典型的部署是用于流处理的消息队列、用于批处理和即席查询的可扫描文件系统/对象存储、以及用于查找的 K-V 存储。但这种架构由于复杂性和异构性，在数据质量和系统维护方面都提出了挑战。正成为影响 Apache Flink 流批统一端到端用户体验的一大问题。</p>
<p>而 Flink Table Store 的目标就是解决上述问题，将 Flink 的能力从计算扩展到存储领域，以便为用户提供更好的端到端体验。</p>
<h2 id="核心能力"><a href="#核心能力" class="headerlink" title="核心能力"></a>核心能力</h2><p>Flink Table Store 旨在提供统一的存储抽象，让用户不必自己构建混合存储。具体来说，Flink Table Store 提供以下核心能力：</p>
<ul>
<li>支持大型数据集的存储，并允许在批处理和流模式下进行读/写；</li>
<li>支持毫秒级延迟的流式查询；</li>
<li>支持秒级延迟 Batch/OLAP 查询；</li>
<li>默认情况下，流消费支持增量快照。所以用户不需要自己解决组合不同存储带来的问题。</li>
</ul>
<h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><p>作为一种新型的可更新数据湖，Flink Table Store 具有以下特点：</p>
<ul>
<li>大吞吐量数据摄取，同时提供良好的查询性能。</li>
<li>具有主键过滤器的高性能查询，最快 100 毫秒。</li>
<li>Lake Storage 上提供流式读取，Lake Storage 也可以与 Kafka 集成，提供秒级流式读取。</li>
</ul>
<h2 id="演进过程"><a href="#演进过程" class="headerlink" title="演进过程"></a>演进过程</h2><p>在早先发布的 0.1.0 预览版，用户可以使用 Flink 将数据写入到 Flink Table Store 中，既可以通过流式传输从数据库中捕获的更新日志，也可以通过从数据仓库等其他存储中批量加载数据。</p>
<p>用户可以使用 Flink 以不同的方式查询 Flink Table Store，包括流式查询和 Batch/OLAP 查询。还值得注意的是，用户也可以使用其他引擎（例如 Apache Hive）从 Flink Table Store 中查询。</p>
<p>在底层，Flink Table Store 使用混合存储架构，使用 Lake Store 存储历史数据，使用 Queue 系统（目前支持 Apache Kafka 集成）存储增量数据。它为混合流式读取提供增量快照。</p>
<p> Flink Table Store 的 Lake Store 将数据作为列文件存储在文件系统/对象存储上，并使用 LSM 结构来支持大量的数据更新和高性能查询。</p>
<p><img src="/image/2022/20220915234511-flink-table-store-architecture.png" alt="Flink Table Store 架构图"></p>
<p>目前，Flink Table Store 发布了 0.2.0 版本。该版本主要包含以下四个值得关注的新特性：</p>
<ol>
<li>引入自己的目录（Catalog），并支持自动同步到 Hive Metastore；</li>
<li>增加对 Flink 1.14 的支持，并支持多个计算引擎（Spark、Hive、Trino）的读取操作；</li>
<li>支持 append-only 表特性；</li>
<li>支持可调整存储桶数量。</li>
</ol>
<p>在即将发布的 0.3.0 版本中，可以期待（至少）以下功能：</p>
<ul>
<li>支持流式变更日志并发写入，Compaction 隔离；</li>
<li>Aggregation Table，用于构建物化视图；</li>
<li>为部分更新/聚合表生成变更日志；</li>
<li>Full Schema Evolution 支持删除列和重命名列；</li>
<li>查找支持 Flink 维度连接。</li>
</ul>
<p>内容来源</p>
<p><a target="_blank" rel="noopener" href="https://flink.apache.org/news/2022/08/29/release-table-store-0.2.0.html">https://flink.apache.org/news/2022/08/29/release-table-store-0.2.0.html</a><br><a target="_blank" rel="noopener" href="https://flink.apache.org/news/2022/05/11/release-table-store-0.1.0.html">https://flink.apache.org/news/2022/05/11/release-table-store-0.1.0.html</a></p>
<p>（END）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2022/09/15/apache-flink-table-store-intro/">http://linjiangxiong.com/2022/09/15/apache-flink-table-store-intro/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a><a class="post-meta__tags" href="/tags/Flink-Table-Store/">Flink Table Store</a></div><div class="post-share"><div class="social-share" data-image="/image/2022/20220915234511-flink-table-store-architecture.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2022/09/16/apache-flink-table-store-quick-start/" title="Apache Flink Table Store 快速入门"><img class="cover" src="/image/2022/20220915234511-flink-table-store-architecture.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Apache Flink Table Store 快速入门</div></div><div class="info-2"><div class="info-item-1">本文通过一个示例来简要介绍如何使用 Apache Flink Table Store。 步骤一：下载 Flink 注意：Flink Table Store 仅从 Flink 1.14 开始支持。  本示例使用的是 Flink 1.15.2 版本，使用 wget 下载： 1wget https://dlcdn.apache.org/flink/flink-1.15.2/flink-1.15.2-bin-scala_2.12.tgz  下载完成之后，解压文件： 1tar -xzf flink-1.15.2-bin-scala_2.12.tgz  本示例中，flink 的安装目录为 /mnt/d/flink-1.15.2 。为便于本文的后续说明，这里使用 ${FLINK_HOME} 代指 flink 的安装目录。 解压后的文件目录如下： 12345678910111213➜  flink-1.15.2 lltotal 616K-rwxrwxrwx 1 root root  12K Aug 17 20:10 LICENSE-rwxrwxrwx 1 root root 600K Aug...</div></div></div></a><a class="pagination-related" href="/2022/09/08/user-portrait-intro/" title="用户画像是什么"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">用户画像是什么</div></div><div class="info-2"><div class="info-item-1">简介在大数据领域，用户画像一般指用户信息标签化。首先，通过多种渠道方式，尽可能多地收集用户各种各样维度的数据，如用户信息、消费水平、消费习惯、购买产品类目偏好等；其次，综合收集到的数据，对用户特征进行刻画与抽象；最后再对这些特征进行分析、统计和推断，挖掘潜在价值。 一个完善的用户画像系统，不仅可以帮助企业进行精细化运营管理，如提升用户购买转化率、商品的曝光/点击率等运营指标，甚至为企业的战略决策提供支持。现在，互联网上常见的针对用户进行个性化推荐、精准营销（如定向广告投放）、个性化服务等，有不少是直接依赖用户画像。例如，不同用户打开同一个外卖 APP，用户极有可能在 APP 首页上看到的是不同的推荐商家，即所谓的“千人千面”，其背后就是用户画像的一个应用场景——根据用户当前所在位置、历史订单数据（口味、消费水平等），给用户打上“标签”，并根据标签给用户推荐合适的商家。 根据打标签的方式，可以将标签分为以下三大类：  统计类标签，通过对用户信息、访问记录、下单消费等常规数据直接进行统计得到，如用户性别、常驻地、年龄、设备类型、近 30 日活跃天数、近 30 日下单天数、近 30...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2023/03/10/lsm-tree-intro/" title="Flink Table Store文件存储结构——LSM树"><img class="cover" src="/image/2023/20230310.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="info-item-2">Flink Table Store文件存储结构——LSM树</div></div><div class="info-2"><div class="info-item-1">本文简要介绍了 Flink Table Store 底层文件存储的数据结构——LSM 树的相关概念。  LSM 树，亦称日志结构合并树，英文为 log-structured merge-tree。  Sorted Runs如下图所示，LSM 树将文件组织成若干个 Sorted Run，一个 Sorted Run 由一个或多个数据文件组成，每个数据文件只会隶属一个 Sorted Run。数据文件中的记录按主键排序，在一个 Sorted Run 中，数据文件的主键范围不会有重叠的情况。但在不同的 Sorted Run 中主键范围有可能会重叠，甚至是包含相同的主键。  当查询 LSM 树时，必须先合并所有的 Sorted Run，根据用户指定的合并引擎和每条记录的时间戳合并具有相同主键的所有记录。而新的记录在写到 LSM 树之前会先缓存在内存中，当内存缓冲区满时，内存中的所有记录会先进行排序，然后再刷到磁盘上，此时就创建了一个新的 Sorted Run。 Compaction随着越来越多的记录写入 LSM 树，Sorted Run 的数量也会越来越多。因为查询 LSM...</div></div></div></a><a class="pagination-related" href="/2022/09/16/apache-flink-table-store-quick-start/" title="Apache Flink Table Store 快速入门"><img class="cover" src="/image/2022/20220915234511-flink-table-store-architecture.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-16</div><div class="info-item-2">Apache Flink Table Store 快速入门</div></div><div class="info-2"><div class="info-item-1">本文通过一个示例来简要介绍如何使用 Apache Flink Table Store。 步骤一：下载 Flink 注意：Flink Table Store 仅从 Flink 1.14 开始支持。  本示例使用的是 Flink 1.15.2 版本，使用 wget 下载： 1wget https://dlcdn.apache.org/flink/flink-1.15.2/flink-1.15.2-bin-scala_2.12.tgz  下载完成之后，解压文件： 1tar -xzf flink-1.15.2-bin-scala_2.12.tgz  本示例中，flink 的安装目录为 /mnt/d/flink-1.15.2 。为便于本文的后续说明，这里使用 ${FLINK_HOME} 代指 flink 的安装目录。 解压后的文件目录如下： 12345678910111213➜  flink-1.15.2 lltotal 616K-rwxrwxrwx 1 root root  12K Aug 17 20:10 LICENSE-rwxrwxrwx 1 root root 600K Aug...</div></div></div></a><a class="pagination-related" href="/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/" title="Lightweight Asynchronous Snapshots for Distributed Dataflows"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="info-item-2">Lightweight Asynchronous Snapshots for Distributed Dataflows</div></div><div class="info-2"><div class="info-item-1">Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}@sics.se3Data Artisans GmbH - {stephan, kostas}@data-artisans.com AbstractDistributed stateful stream processing enables the deployment and execution of large scale continuous omputations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this...</div></div></div></a><a class="pagination-related" href="/2023/09/09/apache-flink-features/" title="Apache Flink的核心特性"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="info-item-2">Apache Flink的核心特性</div></div><div class="info-2"><div class="info-item-1">在大数据和实时数据处理的时代，Apache Flink 以其卓越的性能和灵活性成为了业界的明星。本文将深入探讨这款框架的核心特性，以帮助我们更好地理解其在大数据分析和实时数据处理方面的优势和应用场景。 批流一体Flink 采用了统一的流处理架构，可以用相同的编程模型和运行时系统支持有界数据的批处理和无界数据的实时流处理。这种设计理念使 Flink 在企业技术选型中具有重要意义： 首先，Flink 消除了批处理和流处理之间的鸿沟，企业无需再采用多套框架分别实现两者。这简化了架构设计，降低了系统复杂度。其次，统一的编程模型可以重用批处理和流处理的代码逻辑，提高开发效率。开发人员无需学习多种编程模型，大大减少了学习和开发成本。最后，单一的运行时系统简化了运维工作，无须部署和维护多套框架，可以节省大量运维成本。 也就是说，Flink 的统一流处理架构为企业提供了一个高效、灵活、易于使用的大数据处理解决方案。如果 Flink 能够满足业务需求，就无须用两种甚至多种框架分别实现批处理和流处理，这大大降低了架构设计、开发、运维的复杂度，可以节省大量人力成本。这是 Flink...</div></div></div></a><a class="pagination-related" href="/2023/02/16/flink-sql-table-api-configuration-dependency/" title="Flink依赖配置：Table API &amp; SQL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-16</div><div class="info-item-2">Flink依赖配置：Table API &amp; SQL</div></div><div class="info-2"><div class="info-item-1">我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，所以这里我使用到的 Table API 连接器有 Kafka Connector，Canal Connector。 pom.xml...</div></div></div></a><a class="pagination-related" href="/2023/09/10/apache-flink-history-server/" title="了解Flink中的History Server：记录和展示作业历史信息的重要工具"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="info-item-2">了解Flink中的History Server：记录和展示作业历史信息的重要工具</div></div><div class="info-2"><div class="info-item-1">Flink 中的 History Server 是一个非常有用的组件，可以在相应的 Flink 集群关闭之后查询已完成作业的统计信息。并且，它还提供了一个 REST API，可接受 HTTP 请求并以 JSON 数据作为响应。本文将详细介绍 Flink History Server 的工作原理和主要功能。 一、History Server工作原理Apache Flink 自带了一个 HistoryServer 进程，它是一个独立的 Web 服务器。HistoryServer 不参与 Flink 作业执行，仅用于展示作业的历史信息。它的工作原理如下：  JobManager 会将已完成的作业的信息以存档文件的形式写入 HDFS 或者其他持久存储中。 HistoryServer 读取这些存档文件，并提供 Web 界面展示其信息内容。 用户通过 HistoryServer 的 Web UI 查看作业记录和运行数据。  每个作业完成后，JobManager 会把该作业的信息打包成一个个 JSON 格式的归档文件，包括作业配置信息、作业执行过程中的 Checkpoint...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BA%E7%8E%B0%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">出现背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B"><span class="toc-number">2.</span> <span class="toc-text">核心能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9"><span class="toc-number">3.</span> <span class="toc-text">主要特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BC%94%E8%BF%9B%E8%BF%87%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">演进过程</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/29/multiple-jobs-or-multiple-pipelines-in-one-job-in-flink/" title="Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines">Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines</a><time datetime="2024-10-28T23:10:18.000Z" title="Created 2024-10-29 07:10:18">2024-10-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/18/bulk-deleting-keys-in-redis-using-wildcards/" title="Bulk Deleting Keys in Redis Using Wildcards">Bulk Deleting Keys in Redis Using Wildcards</a><time datetime="2024-09-18T15:42:56.000Z" title="Created 2024-09-18 23:42:56">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"><img src="/image/redis-src/2024091101.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"/></a><div class="content"><a class="title" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing">Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing</a><time datetime="2024-09-10T22:28:03.000Z" title="Created 2024-09-11 06:28:03">2024-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"><img src="/image/redis-src/24091002.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"/></a><div class="content"><a class="title" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation">Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation</a><time datetime="2024-09-09T17:13:55.000Z" title="Created 2024-09-10 01:13:55">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/06/why-does-redis-use-the-sds-structure-for-strings-instead-of-char/" title="Why Does Redis Use the SDS Structure for Strings Instead of char*?">Why Does Redis Use the SDS Structure for Strings Instead of char*?</a><time datetime="2024-09-05T16:01:26.000Z" title="Created 2024-09-06 00:01:26">2024-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>