<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Lightweight Asynchronous Snapshots for Distributed Dataflows | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="keywords" content="Java,JVM,Spring,Spring Boot,Flink,Hadoop,Yarn,MySQL,Elasticsearch,Python,Kafka,Maven,Hbase,Kibana,Logstash,Tutorial,Technical Blogs,Data Structures,Algorithms,C,SQL,Data Science,Web Development,System Design,Interview Experience,Interview Preparation,Programming,Competitive Programming,Coding Contests,HTML,CSS,Computer Science,Programming Examples,Mathematics"><meta name="description" content="Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}">
<meta property="og:type" content="article">
<meta property="og:title" content="Lightweight Asynchronous Snapshots for Distributed Dataflows">
<meta property="og:url" content="http://linjiangxiong.com/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/IMG_3665.JPG">
<meta property="article:published_time" content="2022-10-18T15:18:24.000Z">
<meta property="article:modified_time" content="2022-10-18T15:45:53.140Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Flink">
<meta property="article:tag" content="大数据论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/IMG_3665.JPG"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Lightweight Asynchronous Snapshots for Distributed Dataflows',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-10-18 23:45:53'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">Lightweight Asynchronous Snapshots for Distributed Dataflows</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Lightweight Asynchronous Snapshots for Distributed Dataflows</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-10-18T15:18:24.000Z" title="Created 2022-10-18 23:18:24">2022-10-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-10-18T15:45:53.140Z" title="Updated 2022-10-18 23:45:53">2022-10-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BC%96%E7%A8%8B%E6%96%87%E6%91%98/">编程文摘</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h2><p>皇家理工学院</p>
<p>Paris Carbone1 Gyula Fora ´<br>2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas3<br>1KTH Royal Institute of Technology - {parisc,haridi}@kth.se<br>2Swedish Institute of Computer Science - {gyfora, seif}@sics.se<br>3Data Artisans GmbH - {stephan, kostas}@data-artisans.com</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Distributed stateful stream processing enables the deployment and execution of large scale continuous omputations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this paradigm is providing processing guarantees under potential failures. Existing approaches rely on periodic global state snapshots that can be used for failure recovery. Those approaches suffer from two main drawbacks. First, they often stall the overall computation which impacts ingestion. Second, they eagerly persist all records in transit along with the operation states which results in larger snapshots than required. In this work we propose Asynchronous Barrier Snapshotting (ABS), a lightweight algorithm suited for modern dataflow execution engines that minimises space requirements. ABS persists only operator states on acyclic execution topologies while keeping a minimal record log on cyclic dataflows. We implemented ABS on Apache Flink, a distributed analytics engine that supports stateful stream processing. Our evaluation shows that our algorithm does not have a heavy impact on the execution, maintaining linear scalability and performing well with frequent snapshots.</p>
<p><strong>Keywords</strong> fault tolerance, distributed computing, stream processing, dataflow, cloud computing, state management</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>Distributed dataflow processing is an emerging paradigm for data intensive computing which allows continuous computations on data in high volumes, targeting low end-to-end latency while guaranteeing high throughput. Several time-critical applications could benefit from dataflow processing systems such as Apache Flink [1] and Naiad [11], especially in the domains of real-time analysis (e.g. predictive analytics and complex event processing). Fault tolerance is of paramount importance in such systems, as failures cannot be afforded in most real-world use cases. Currently known approaches that guarantee exactly-once semantics on stateful processing systems rely on global, consistent snapshots of the execution state. However, there are two main drawbacks that make their application inefficient for real-time stream processing. Synchronous snapshotting techniques stop the overall execution of a distributed computation in order to obtain a consistent view of the overall state. Furthermore, to our knowledge all of the existing algorithms for distributed snapshots include records that are in transit in channels or unprocessed messages throughout the execution graph as part of the snapshotted state. Most often this includes state that is larger than required.<br>In this work, we focus on providing lightweight snapshotting, specifically targeted at distributed stateful dataflow systems, with low impact on performance. Our solution provides asynchronous state snapshots with low space costs that contain only operator states in acyclic execution topologies. Additionally, we cover the case of cyclic execution graphs by applying downstream backup on selected parts of the topology while keeping the snapshot state to minimum. Our technique does not halt the streaming operation and it only introduces a small runtime overhead. The contributions of this paper can be summarised as follows:</p>
<ul>
<li>We propose and implement an asynchronous snapshotting algorithm that achieves minimal snapshots on acyclic execution graphs.</li>
<li>We describe and implement a generalisation of our algorithm that works on cyclic execution graphs.</li>
<li>We show the benefits of our approach compared to the state-of-the-art using Apache Flink Streaming as a base system for comparisons.</li>
</ul>
<p>The rest of the paper is organised as follows: Section 2 gives an overview of existing approaches for distributed global snapshots in stateful dataflow systems. Section 3 provides an overview of the Apache Flink processing and execution model followed by Section 4 where we describe our main approach to global snapshotting in detail. Our recovery scheme is described briefly in Section 5. Finally, Section 6 summarises our implementation followed by our evaluation in Section 7 and future work and conclusion in Section 8.</p>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p>Several recovery mechanisms have been proposed during the last decade for systems that do continuous processing [4, 11]. Systems that emulate continuous processing into stateless distributed batch computations such as Discretized Streams and Comet [6, 15] rely on state recomputation. On the other hand, stateful dataflow systems such as Naiad, SDGs, Piccolo and SEEP [3, 5, 11, 12] , which are our main focus in this work, use checkpointing to obtain consistent snapshots of the global execution for failure recovery.</p>
<p>The problem of consistent global snapshots in distributed environments, as introduced by Chandy and Lamport [4], has been researched extensively throughout the last decades [4, 7, 8]. A global snapshot theoretically reflects the overall state of an execution, or a possible state at a specific instance of its operation. A simple but costly approach employed by Naiad [11] is to perform a synchronous snapshot in three steps: first halting the overall computation of the execution graph, then performing the snapshot and finally instructing each task to continue its operation once the global snapshot is complete. This approach has a high impact on both throughput and space requirements due to the need to block the whole computation, while also relying on upstream backup that logs emitted records at the producer side. Another popular approach, originally proposed by Chandy and Lamport [4], that is deployed in many systems today is to perform snapshots asynchronously while eagerly doing upstream backup [4, 5, 10]. This is achieved by distributing markers throughout the execution graph that trigger the persistence of operator and channel state. This approach though still suffers from additional space requirements due to the need of an upstream backup and as a result higher recovery times caused by the reprocessing of backup records. Our approach extends the original asynchronous snapshotting idea of Chandy and Lamport, however, it considers no backup logging of records for acyclic graphs while also keeping very selective backup records on cyclic execution graphs.</p>
<h2 id="3-Background-The-Apache-Flink-System"><a href="#3-Background-The-Apache-Flink-System" class="headerlink" title="3. Background: The Apache Flink System"></a>3. Background: The Apache Flink System</h2><p>Our current work is guided by the need for fault tolerance on Apache Flink Streaming, a distributed stream analytics system that is part of the Apache Flink Stack (former Stratosphere [2]). Apache Flink is architectured around a generic runtime engine uniformly processing both batch and streaming jobs composed of stateful interconnected tasks. Analytics jobs in Flink are compiled into directed graphs of tasks. Data elements are fetched from external sources and routed through the task graph in a pipelined fashion. Tasks are continuously manipulating their internal state based on the received inputs and are generating new outputs.</p>
<h3 id="3-1-The-Streaming-Programming-Model"><a href="#3-1-The-Streaming-Programming-Model" class="headerlink" title="3.1 The Streaming Programming Model"></a>3.1 The Streaming Programming Model</h3><p>The Apache Flink API for stream processing allows the composition of complex streaming analytics jobs by exposing unbounded partitioned data streams (partially ordered sequences of records) as its core data abstraction, called DataStreams. DataStreams can be created from external sources (e.g. message queues, socket streams, custom generators) or by invoking operations on other DataStreams. DataStreams support several operators such as map, filter and reduce in the form of higher order functions that are applied incrementally per record and generate new DataStreams. Every operator can be parallelised by placing parallel instances to run on different partitions of the respective stream, thus, allowing the distributed execution of stream transformations.</p>
<p>The code example in 1 shows how to implement a simple incremental word count in Apache Flink. In this program words are read from a text file and the current count for each word is printed to the standard output. This is a stateful streaming program as sources need to be aware of their current file offset and counters need to maintain the current count for each word as their internal state.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1acd798f-a4ed-45db-968a-b2bc5c06882a/Untitled.png" alt="Figure 1: The execution graph for incremental word count"></p>
<p>Figure 1: The execution graph for incremental word count</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> env : <span class="type">StreamExecutionEnvironment</span> = ...</span><br><span class="line">env.setParallelism(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> wordStream = env.readTextFile(path)</span><br><span class="line"><span class="keyword">val</span> countStream = wordStream.groupBy(_).count</span><br><span class="line">countStream.print</span><br></pre></td></tr></table></figure>

<p>Example 1: Incremental Word Count</p>
<h3 id="3-2-Distributed-Dataflow-Execution"><a href="#3-2-Distributed-Dataflow-Execution" class="headerlink" title="3.2 Distributed Dataflow Execution"></a>3.2 Distributed Dataflow Execution</h3><p>When a user executes an application all DataStream operators compile into an execution graph that is in principle a directed graph $G=(T, E)$ , similarly to Naiad [11] where vertices $T$ represent tasks and edges $E$ represent data channels between tasks. An execution graph is depicted in Fig. 1 for the incremental word count example. As shown, every instance of an operator is encapsulated on a respective task. Tasks can be further classified as sources when they have no input channels and sinks when no output channels are set. Furthermore, $M$ denotes the set of all records transferred by tasks during their parallel execution. Each task $t\in T$ encapsulates the independent execution of an operator instance and is composed of the following: (1) a set of input and output channels: $I_t, O_t \subseteq E$; (2) an operator state $s_t$ and (3) a user defined function (UDF) $f_t$. Data ingestion is pull-based : during its execution each task consumes input records, updates its operator state and generates new records according to its user defined function. </p>
<p>More specifically, for each record $r\in M$ received by a task $t\in T$ a new state $s^{’}_t$ </p>
<dl><dt>0<br>t<br>is produced along<br>with a set of output records D ⊆ M according to its<br>UDF ft</dt><dd>st<br>,r 7→ hs<br>0<br>t<br>,Di.</dd></dl><p>$$<br>fafas<br>$$</p>
<p>$\dot{a}$</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/">http://linjiangxiong.com/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AE%BA%E6%96%87/">大数据论文</a></div><div class="post-share"><div class="social-share" data-image="/image/IMG_3665.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2022/10/21/how-to-enable-mysql-binlog/" title="MySQL如何开启binlog日志"><img class="cover" src="/image/brand/mysql.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">MySQL如何开启binlog日志</div></div><div class="info-2"><div class="info-item-1">查看是否开启binlog日志连接 MySQL，执行以下命令： 1show variables like &#x27;log_%&#x27;;  查询结果类似以下内容：    Variable_name Value    log_bin OFF   log_bin_basename    log_bin_index    …    变量 log_bin 的值为 OFF，说明未开启 binlog 日志，若为 ON 说明已开启。 开启binlog日志若 MySQL 未开启 binlog 日志，可通过修改 MySQL 的配置文件 mysqld.cnf 启用 binlog 日志。 打开配置文件（注意：配置文件位置需改为你自己的存放位置）： 1vim /etc/mysql/mysql.conf.d/mysqld.cnf  添加以下配置项： 123server_id       = 20log_bin         = mysql-binbinlog_format   = ROW  保存修改内容，并重新启动 MySQL 使修改后的配置项生效，如使用 service...</div></div></div></a><a class="pagination-related" href="/2022/10/14/query-dsl-null-field/" title="【Elasticsearch】Query DSL查询指定字段值为null的文档"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">【Elasticsearch】Query DSL查询指定字段值为null的文档</div></div><div class="info-2"><div class="info-item-1">Hey，大家好！我是 Elasticsearch 新手。我想知道如何通过 Query DSL 找出指定字段值为 null 的文档。 以下是我索引（索引名：class_info_v22002，用来存放班级信息）创建的 DSL： 123456789101112131415161718192021PUT class_info_v22002&#123;  &quot;settings&quot;: &#123;    &quot;refresh_interval&quot;: &quot;1s&quot;,    &quot;number_of_replicas&quot;: 1,    &quot;number_of_shards&quot;: 3  &#125;,   &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;class_id&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;,     ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2023/09/09/apache-flink-features/" title="Apache Flink的核心特性"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="info-item-2">Apache Flink的核心特性</div></div><div class="info-2"><div class="info-item-1">在大数据和实时数据处理的时代，Apache Flink 以其卓越的性能和灵活性成为了业界的明星。本文将深入探讨这款框架的核心特性，以帮助我们更好地理解其在大数据分析和实时数据处理方面的优势和应用场景。 批流一体Flink 采用了统一的流处理架构，可以用相同的编程模型和运行时系统支持有界数据的批处理和无界数据的实时流处理。这种设计理念使 Flink 在企业技术选型中具有重要意义： 首先，Flink 消除了批处理和流处理之间的鸿沟，企业无需再采用多套框架分别实现两者。这简化了架构设计，降低了系统复杂度。其次，统一的编程模型可以重用批处理和流处理的代码逻辑，提高开发效率。开发人员无需学习多种编程模型，大大减少了学习和开发成本。最后，单一的运行时系统简化了运维工作，无须部署和维护多套框架，可以节省大量运维成本。 也就是说，Flink 的统一流处理架构为企业提供了一个高效、灵活、易于使用的大数据处理解决方案。如果 Flink 能够满足业务需求，就无须用两种甚至多种框架分别实现批处理和流处理，这大大降低了架构设计、开发、运维的复杂度，可以节省大量人力成本。这是 Flink...</div></div></div></a><a class="pagination-related" href="/2023/03/10/lsm-tree-intro/" title="Flink Table Store文件存储结构——LSM树"><img class="cover" src="/image/2023/20230310.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="info-item-2">Flink Table Store文件存储结构——LSM树</div></div><div class="info-2"><div class="info-item-1">本文简要介绍了 Flink Table Store 底层文件存储的数据结构——LSM 树的相关概念。  LSM 树，亦称日志结构合并树，英文为 log-structured merge-tree。  Sorted Runs如下图所示，LSM 树将文件组织成若干个 Sorted Run，一个 Sorted Run 由一个或多个数据文件组成，每个数据文件只会隶属一个 Sorted Run。数据文件中的记录按主键排序，在一个 Sorted Run 中，数据文件的主键范围不会有重叠的情况。但在不同的 Sorted Run 中主键范围有可能会重叠，甚至是包含相同的主键。  当查询 LSM 树时，必须先合并所有的 Sorted Run，根据用户指定的合并引擎和每条记录的时间戳合并具有相同主键的所有记录。而新的记录在写到 LSM 树之前会先缓存在内存中，当内存缓冲区满时，内存中的所有记录会先进行排序，然后再刷到磁盘上，此时就创建了一个新的 Sorted Run。 Compaction随着越来越多的记录写入 LSM 树，Sorted Run 的数量也会越来越多。因为查询 LSM...</div></div></div></a><a class="pagination-related" href="/2023/02/16/flink-sql-table-api-configuration-dependency/" title="Flink依赖配置：Table API &amp; SQL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-16</div><div class="info-item-2">Flink依赖配置：Table API &amp; SQL</div></div><div class="info-2"><div class="info-item-1">我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，所以这里我使用到的 Table API 连接器有 Kafka Connector，Canal Connector。 pom.xml...</div></div></div></a><a class="pagination-related" href="/2023/09/10/apache-flink-history-server/" title="了解Flink中的History Server：记录和展示作业历史信息的重要工具"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="info-item-2">了解Flink中的History Server：记录和展示作业历史信息的重要工具</div></div><div class="info-2"><div class="info-item-1">Flink 中的 History Server 是一个非常有用的组件，可以在相应的 Flink 集群关闭之后查询已完成作业的统计信息。并且，它还提供了一个 REST API，可接受 HTTP 请求并以 JSON 数据作为响应。本文将详细介绍 Flink History Server 的工作原理和主要功能。 一、History Server工作原理Apache Flink 自带了一个 HistoryServer 进程，它是一个独立的 Web 服务器。HistoryServer 不参与 Flink 作业执行，仅用于展示作业的历史信息。它的工作原理如下：  JobManager 会将已完成的作业的信息以存档文件的形式写入 HDFS 或者其他持久存储中。 HistoryServer 读取这些存档文件，并提供 Web 界面展示其信息内容。 用户通过 HistoryServer 的 Web UI 查看作业记录和运行数据。  每个作业完成后，JobManager 会把该作业的信息打包成一个个 JSON 格式的归档文件，包括作业配置信息、作业执行过程中的 Checkpoint...</div></div></div></a><a class="pagination-related" href="/2023/09/01/apache-flink-use-cases/" title="探究Apache Flink支持的三种流处理场景"><img class="cover" src="/image/2023/20230901-image1.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-01</div><div class="info-item-2">探究Apache Flink支持的三种流处理场景</div></div><div class="info-2"><div class="info-item-1">Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实际上，Flink 能够扩展到数千个内核和 TB 级的应用状态，提供高吞吐量和低延迟，并为世界上一些要求最苛刻的流处理应用提供支持。 本文将介绍 Flink...</div></div></div></a><a class="pagination-related" href="/2023/09/02/apache-flink-performance-high-throughput-low-latency/" title="探索流式应用的性能指标：延迟和吞吐量解析"><img class="cover" src="/image/brand/flink-header-logo.svg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-02</div><div class="info-item-2">探索流式应用的性能指标：延迟和吞吐量解析</div></div><div class="info-2"><div class="info-item-1">批处理应用和流式应用在性能需求上有所区别。对于批处理应用而言，我们通常关心作业的总执行时间，即从处理引擎读取输入、执行计算、写回结果所需的时间。但在数据流处理中，由于流式应用会持续执行且输入可能是无限的，所以没有总执行时间的概念。相反，流式应用需要尽可能快地计算结果，并能处理高速的事件接入。因此，我们用延迟和吞吐来表示这两方面的性能需求。 延迟延迟是指处理一个事件所需的时间，从接收事件到在输出中观察到事件处理效果的时间间隔。为了更直观地理解延迟，我们可以以去咖啡店喝咖啡为例。当你进门时，可能已经有其他顾客在里面了，需要排队等候。收银员收到你的付款后，将订单交给咖啡师准备饮品。饮品制作完成后，咖啡师会叫你的名字，你才能从吧台取走咖啡。在这个过程中，你在店内买咖啡的时间就是服务延迟，即从进门到喝到第一口咖啡的时间。 在流处理中，我们用时间片（如毫秒）来测量延迟。根据应用的不同，我们可能关注平均延迟、最大延迟或特定百分位数的延迟。例如，平均延迟为 10 毫秒表示平均每条数据在 10 毫秒内处理完毕，而第 95 百分位延迟在 10 毫秒内处理完毕意味着 95% 的事件都在 10...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Author"><span class="toc-number">1.</span> <span class="toc-text">Author</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">2.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-number">3.</span> <span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Related-Work"><span class="toc-number">4.</span> <span class="toc-text">2. Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Background-The-Apache-Flink-System"><span class="toc-number">5.</span> <span class="toc-text">3. Background: The Apache Flink System</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-The-Streaming-Programming-Model"><span class="toc-number">5.1.</span> <span class="toc-text">3.1 The Streaming Programming Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Distributed-Dataflow-Execution"><span class="toc-number">5.2.</span> <span class="toc-text">3.2 Distributed Dataflow Execution</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/29/multiple-jobs-or-multiple-pipelines-in-one-job-in-flink/" title="Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines">Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines</a><time datetime="2024-10-28T23:10:18.000Z" title="Created 2024-10-29 07:10:18">2024-10-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/18/bulk-deleting-keys-in-redis-using-wildcards/" title="Bulk Deleting Keys in Redis Using Wildcards">Bulk Deleting Keys in Redis Using Wildcards</a><time datetime="2024-09-18T15:42:56.000Z" title="Created 2024-09-18 23:42:56">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"><img src="/image/redis-src/2024091101.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"/></a><div class="content"><a class="title" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing">Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing</a><time datetime="2024-09-10T22:28:03.000Z" title="Created 2024-09-11 06:28:03">2024-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"><img src="/image/redis-src/24091002.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"/></a><div class="content"><a class="title" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation">Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation</a><time datetime="2024-09-09T17:13:55.000Z" title="Created 2024-09-10 01:13:55">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/06/why-does-redis-use-the-sds-structure-for-strings-instead-of-char/" title="Why Does Redis Use the SDS Structure for Strings Instead of char*?">Why Does Redis Use the SDS Structure for Strings Instead of char*?</a><time datetime="2024-09-05T16:01:26.000Z" title="Created 2024-09-06 00:01:26">2024-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>