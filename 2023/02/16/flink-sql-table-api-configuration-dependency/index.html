<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Flink依赖配置：Table API &amp; SQL | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="keywords" content="Java,JVM,Spring,Spring Boot,Flink,Hadoop,Yarn,MySQL,Elasticsearch,Python,Kafka,Maven,Hbase,Kibana,Logstash,Tutorial,Technical Blogs,Data Structures,Algorithms,C,SQL,Data Science,Web Development,System Design,Interview Experience,Interview Preparation,Programming,Competitive Programming,Coding Contests,HTML,CSS,Computer Science,Programming Examples,Mathematics"><meta name="description" content="我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink依赖配置：Table API &amp; SQL">
<meta property="og:url" content="http://linjiangxiong.com/2023/02/16/flink-sql-table-api-configuration-dependency/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/IMG_3665.JPG">
<meta property="article:published_time" content="2023-02-16T15:17:57.000Z">
<meta property="article:modified_time" content="2023-03-22T15:51:18.655Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/IMG_3665.JPG"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2023/02/16/flink-sql-table-api-configuration-dependency/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Flink依赖配置：Table API & SQL',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-03-22 23:51:18'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">294</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">Flink依赖配置：Table API &amp; SQL</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Flink依赖配置：Table API &amp; SQL</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-02-16T15:17:57.000Z" title="Created 2023-02-16 23:17:57">2023-02-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-22T15:51:18.655Z" title="Updated 2023-03-22 23:51:18">2023-03-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BC%96%E7%A8%8B-Q-A/">编程 Q&amp;A</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><p>我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。</p>
<p>程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，所以这里我使用到的 Table API 连接器有 Kafka Connector，Canal Connector。</p>
<p>pom.xml 依赖如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-slf4j-impl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 以下三个依赖是我自己添加的 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner-loader<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.16.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-runtime<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.16.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>程序代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="type">EnvironmentSettings</span> <span class="variable">settings</span> <span class="operator">=</span> EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line">                .inStreamingMode()</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">TableConfig</span> <span class="variable">tableConfig</span> <span class="operator">=</span> TableConfig.getDefault();</span><br><span class="line">        tableConfig.setIdleStateRetention(Duration.ofDays(<span class="number">1L</span>));</span><br><span class="line">        <span class="type">TableEnvironment</span> <span class="variable">tableEnv</span> <span class="operator">=</span> TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;CREATE TABLE `tb_user` ( &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `id` INT, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `area_code` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `phone` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `password` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `nickname` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `avatar` STRING &quot;</span> +</span><br><span class="line">                <span class="string">&quot;) WITH ( &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;connector&#x27; = &#x27;kafka&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;topic&#x27; = &#x27;dwd_user&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;properties.bootstrap.servers&#x27; = &#x27;kafka1:9092,kafka2:9092,kafka3:9092&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;properties.group.id&#x27; = &#x27;dwd_user_v230215&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;scan.startup.mode&#x27; = &#x27;earliest-offset&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;format&#x27; = &#x27;canal-json&#x27; &quot;</span> +</span><br><span class="line">                <span class="string">&quot;)&quot;</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> tableEnv.sqlQuery(<span class="string">&quot;select * from tb_user&quot;</span>);</span><br><span class="line">        table.printSchema();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里要把 Table 转成流进行打印输出，但这里缺少相关方法，编译不通过？</span></span><br><span class="line">        DataStream&lt;Row&gt; resultStream = tableEnv.from(table);</span><br><span class="line"></span><br><span class="line">        resultStream.print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">&quot;TT&quot;</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<hr>
<p>上面代码中，Flink SQL 所使用的 Kafka 连接器和解析 Canal Json 格式的连接器的依赖是对的。</p>
<p>Flink Table API 的 Kafka 连接器依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Flink Table API 的 Canal Json 解析连接器依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>因为你的应用中需要将 Table 类型转为 DataStream 类型进行打印输出，即需要混合使用 DataStream API 和 Table API &amp; SQL 这两种类型 API，那么你需要添加的是 flink-table-api-java-bridge 依赖，而不是 flink-table-api-java 依赖。</p>
<p>flink-table-api-java-bridge 依赖如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java-bridge<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.16.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>修改完依赖后，你的应用程序代码修改如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="type">EnvironmentSettings</span> <span class="variable">settings</span> <span class="operator">=</span> EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line">                .inStreamingMode()</span><br><span class="line">                .build();</span><br><span class="line">        <span class="type">TableConfig</span> <span class="variable">tableConfig</span> <span class="operator">=</span> TableConfig.getDefault();</span><br><span class="line">        tableConfig.setIdleStateRetention(Duration.ofDays(<span class="number">1L</span>));</span><br><span class="line">        **<span class="type">StreamTableEnvironment</span> <span class="variable">tableEnv</span> <span class="operator">=</span> StreamTableEnvironmentImpl.create(env, settings);**</span><br><span class="line"></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;CREATE TABLE `tb_user` ( &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `id` INT, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `area_code` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `phone` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `password` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `nickname` STRING, &quot;</span> +</span><br><span class="line">                <span class="string">&quot;  `avatar` STRING &quot;</span> +</span><br><span class="line">                <span class="string">&quot;) WITH ( &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;connector&#x27; = &#x27;kafka&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;topic&#x27; = &#x27;dwd_user&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;properties.bootstrap.servers&#x27; = &#x27;kafka1:9092,kafka2:9092,kafka3:9092&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;properties.group.id&#x27; = &#x27;dwd_user_v230215&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;scan.startup.mode&#x27; = &#x27;earliest-offset&#x27;, &quot;</span> +</span><br><span class="line">                <span class="string">&quot; &#x27;format&#x27; = &#x27;canal-json&#x27; &quot;</span> +</span><br><span class="line">                <span class="string">&quot;)&quot;</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> tableEnv.sqlQuery(<span class="string">&quot;select * from tb_user&quot;</span>);</span><br><span class="line">        table.printSchema();</span><br><span class="line"></span><br><span class="line">        **DataStream&lt;Row&gt; resultStream = tableEnv.toChangelogStream(table);**</span><br><span class="line"></span><br><span class="line">        resultStream.print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">&quot;TT&quot;</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>NOTE：Flink 提供了两种主要的 API：Datastream API 和 Table API &amp; SQL。根据你的使用场景，它们既可以单独使用，也可以混合使用。</p>
<p>API 与依赖项对应如下：</p>
<table>
<thead>
<tr>
<th>要使用的 API</th>
<th>需要添加的依赖项</th>
</tr>
</thead>
<tbody><tr>
<td>DataStream</td>
<td>flink-streaming-java</td>
</tr>
<tr>
<td>DataStream with Scala</td>
<td>flink-streaming-scala_2.12</td>
</tr>
<tr>
<td>Table API</td>
<td>flink-table-api-java</td>
</tr>
<tr>
<td>Table API with Scala</td>
<td>flink-table-api-scala_2.12</td>
</tr>
<tr>
<td>Table API + DataStream</td>
<td>flink-table-api-java-bridge</td>
</tr>
<tr>
<td>Table API + DataStream with Scala</td>
<td>flink-table-api-scala-bridge_2.12</td>
</tr>
</tbody></table>
<p>这里 API 按 Java 还是 Scala 语言，是单独使用还是混合使用，划分为六个依赖项，具体使用哪个 API，取决于你的应用场景。</p>
<p>（END）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2023/02/16/flink-sql-table-api-configuration-dependency/">http://linjiangxiong.com/2023/02/16/flink-sql-table-api-configuration-dependency/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a></div><div class="post-share"><div class="social-share" data-image="/image/IMG_3665.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2023/02/20/filebeat-introduction/" title="了解Filebeat：采集、转发和汇总日志的轻量型解决方案"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">了解Filebeat：采集、转发和汇总日志的轻量型解决方案</div></div><div class="info-2"><div class="info-item-1">Filebeat 是什么？Filebeat 是基于 libbeat 框架开发的一款开源的轻量型日志采集器，专为快速收集和传输多种来源的日志数据而设计。它可以从安全设备、云、容器、主机或 OT 等多种数据源采集日志，并提供一种轻量型的方法，用于转发和汇总日志与文件。 Filebeat 有什么特点？1、Filebeat 支持从多种数据源收集数据，例如安全设备、云服务、容器、主机或 OT等。 2、Filebeat 具有性能稳定、支持容错机制的特点。如果在未来某个时刻 Filebeat 因为某种原因中断，恢复正常后，它可以从中断前停止的位置继续读取并转发日志行。 3、Filebeat 支持背压机制。这意味着，如果 Filebeat 发送日志数据的速率超过接收端（例如 Logstash、Elasticsearch等）处理数据的速率，接收端会向 Filebeat 发出信号，要求 Filebeat 减慢发送速度，以避免 Filebeat 收集的数据因内存不足而被丢弃。一旦接收端处理数据的速率跟上，Filebeat 就会恢复到原来的步伐并继续传输数据。 4、Filebeat...</div></div></div></a><a class="pagination-related" href="/2023/01/13/superset-presto-error-prestoenginespec/" title="Superset配置——连接Presto出现ERROR: Could not load database driver: PrestoEngineSpec"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Superset配置——连接Presto出现ERROR: Could not load database driver: PrestoEngineSpec</div></div><div class="info-2"><div class="info-item-1">问题描述安装好 superset，版本 2.0.1，通过命令 superset run -p 8088 --with-threads --reload --debugger 启动 debug 模式，在界面配置 presto 数据库连接，点击 TEST CONNECTION，右下角弹出以下错误信息： 1ERROR: Could not load database driver: PrestoEngineSpec  在启动 superset 之前，服务器上已按照官方文档安装了驱动： 1pip3 install pyhive  解决方法从错误信息可以看出这是驱动问题导致的。虽然安装了正确的驱动，但是如果驱动的版本太低，同样也会有问题。通过 pip 安装默认都是最新版本，截至当前，pyhive 的最新版本为 0.6.5。 首先检查服务器上安装的 pyhive 的版本是否为最新的版本： 1pip3 list  或： 12$ pip3 list |grep PyHivePyHive                 0.6.5  可以看到 PyHive 为最新版本...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/" title="Lightweight Asynchronous Snapshots for Distributed Dataflows"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="info-item-2">Lightweight Asynchronous Snapshots for Distributed Dataflows</div></div><div class="info-2"><div class="info-item-1">Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}@sics.se3Data Artisans GmbH - {stephan, kostas}@data-artisans.com AbstractDistributed stateful stream processing enables the deployment and execution of large scale continuous omputations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this...</div></div></div></a><a class="pagination-related" href="/2023/09/09/apache-flink-features/" title="Apache Flink的核心特性"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="info-item-2">Apache Flink的核心特性</div></div><div class="info-2"><div class="info-item-1">在大数据和实时数据处理的时代，Apache Flink 以其卓越的性能和灵活性成为了业界的明星。本文将深入探讨这款框架的核心特性，以帮助我们更好地理解其在大数据分析和实时数据处理方面的优势和应用场景。 批流一体Flink 采用了统一的流处理架构，可以用相同的编程模型和运行时系统支持有界数据的批处理和无界数据的实时流处理。这种设计理念使 Flink 在企业技术选型中具有重要意义： 首先，Flink 消除了批处理和流处理之间的鸿沟，企业无需再采用多套框架分别实现两者。这简化了架构设计，降低了系统复杂度。其次，统一的编程模型可以重用批处理和流处理的代码逻辑，提高开发效率。开发人员无需学习多种编程模型，大大减少了学习和开发成本。最后，单一的运行时系统简化了运维工作，无须部署和维护多套框架，可以节省大量运维成本。 也就是说，Flink 的统一流处理架构为企业提供了一个高效、灵活、易于使用的大数据处理解决方案。如果 Flink 能够满足业务需求，就无须用两种甚至多种框架分别实现批处理和流处理，这大大降低了架构设计、开发、运维的复杂度，可以节省大量人力成本。这是 Flink...</div></div></div></a><a class="pagination-related" href="/2023/03/10/lsm-tree-intro/" title="Flink Table Store文件存储结构——LSM树"><img class="cover" src="/image/2023/20230310.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="info-item-2">Flink Table Store文件存储结构——LSM树</div></div><div class="info-2"><div class="info-item-1">本文简要介绍了 Flink Table Store 底层文件存储的数据结构——LSM 树的相关概念。  LSM 树，亦称日志结构合并树，英文为 log-structured merge-tree。  Sorted Runs如下图所示，LSM 树将文件组织成若干个 Sorted Run，一个 Sorted Run 由一个或多个数据文件组成，每个数据文件只会隶属一个 Sorted Run。数据文件中的记录按主键排序，在一个 Sorted Run 中，数据文件的主键范围不会有重叠的情况。但在不同的 Sorted Run 中主键范围有可能会重叠，甚至是包含相同的主键。  当查询 LSM 树时，必须先合并所有的 Sorted Run，根据用户指定的合并引擎和每条记录的时间戳合并具有相同主键的所有记录。而新的记录在写到 LSM 树之前会先缓存在内存中，当内存缓冲区满时，内存中的所有记录会先进行排序，然后再刷到磁盘上，此时就创建了一个新的 Sorted Run。 Compaction随着越来越多的记录写入 LSM 树，Sorted Run 的数量也会越来越多。因为查询 LSM...</div></div></div></a><a class="pagination-related" href="/2023/09/10/apache-flink-history-server/" title="了解Flink中的History Server：记录和展示作业历史信息的重要工具"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="info-item-2">了解Flink中的History Server：记录和展示作业历史信息的重要工具</div></div><div class="info-2"><div class="info-item-1">Flink 中的 History Server 是一个非常有用的组件，可以在相应的 Flink 集群关闭之后查询已完成作业的统计信息。并且，它还提供了一个 REST API，可接受 HTTP 请求并以 JSON 数据作为响应。本文将详细介绍 Flink History Server 的工作原理和主要功能。 一、History Server工作原理Apache Flink 自带了一个 HistoryServer 进程，它是一个独立的 Web 服务器。HistoryServer 不参与 Flink 作业执行，仅用于展示作业的历史信息。它的工作原理如下：  JobManager 会将已完成的作业的信息以存档文件的形式写入 HDFS 或者其他持久存储中。 HistoryServer 读取这些存档文件，并提供 Web 界面展示其信息内容。 用户通过 HistoryServer 的 Web UI 查看作业记录和运行数据。  每个作业完成后，JobManager 会把该作业的信息打包成一个个 JSON 格式的归档文件，包括作业配置信息、作业执行过程中的 Checkpoint...</div></div></div></a><a class="pagination-related" href="/2023/09/01/apache-flink-use-cases/" title="探究Apache Flink支持的三种流处理场景"><img class="cover" src="/image/2023/20230901-image1.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-01</div><div class="info-item-2">探究Apache Flink支持的三种流处理场景</div></div><div class="info-2"><div class="info-item-1">Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实际上，Flink 能够扩展到数千个内核和 TB 级的应用状态，提供高吞吐量和低延迟，并为世界上一些要求最苛刻的流处理应用提供支持。 本文将介绍 Flink...</div></div></div></a><a class="pagination-related" href="/2023/09/02/apache-flink-performance-high-throughput-low-latency/" title="探索流式应用的性能指标：延迟和吞吐量解析"><img class="cover" src="/image/brand/flink-header-logo.svg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-02</div><div class="info-item-2">探索流式应用的性能指标：延迟和吞吐量解析</div></div><div class="info-2"><div class="info-item-1">批处理应用和流式应用在性能需求上有所区别。对于批处理应用而言，我们通常关心作业的总执行时间，即从处理引擎读取输入、执行计算、写回结果所需的时间。但在数据流处理中，由于流式应用会持续执行且输入可能是无限的，所以没有总执行时间的概念。相反，流式应用需要尽可能快地计算结果，并能处理高速的事件接入。因此，我们用延迟和吞吐来表示这两方面的性能需求。 延迟延迟是指处理一个事件所需的时间，从接收事件到在输出中观察到事件处理效果的时间间隔。为了更直观地理解延迟，我们可以以去咖啡店喝咖啡为例。当你进门时，可能已经有其他顾客在里面了，需要排队等候。收银员收到你的付款后，将订单交给咖啡师准备饮品。饮品制作完成后，咖啡师会叫你的名字，你才能从吧台取走咖啡。在这个过程中，你在店内买咖啡的时间就是服务延迟，即从进门到喝到第一口咖啡的时间。 在流处理中，我们用时间片（如毫秒）来测量延迟。根据应用的不同，我们可能关注平均延迟、最大延迟或特定百分位数的延迟。例如，平均延迟为 10 毫秒表示平均每条数据在 10 毫秒内处理完毕，而第 95 百分位延迟在 10 毫秒内处理完毕意味着 95% 的事件都在 10...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">294</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/18/bulk-deleting-keys-in-redis-using-wildcards/" title="Bulk Deleting Keys in Redis Using Wildcards">Bulk Deleting Keys in Redis Using Wildcards</a><time datetime="2024-09-18T15:42:56.000Z" title="Created 2024-09-18 23:42:56">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"><img src="/image/redis-src/2024091101.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"/></a><div class="content"><a class="title" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing">Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing</a><time datetime="2024-09-10T22:28:03.000Z" title="Created 2024-09-11 06:28:03">2024-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"><img src="/image/redis-src/24091002.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"/></a><div class="content"><a class="title" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation">Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation</a><time datetime="2024-09-09T17:13:55.000Z" title="Created 2024-09-10 01:13:55">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/06/why-does-redis-use-the-sds-structure-for-strings-instead-of-char/" title="Why Does Redis Use the SDS Structure for Strings Instead of char*?">Why Does Redis Use the SDS Structure for Strings Instead of char*?</a><time datetime="2024-09-05T16:01:26.000Z" title="Created 2024-09-06 00:01:26">2024-09-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/05/how-to-delete-data-in-elasticsearch-single-multiple-clear-and-all/" title="How to Delete Data in Elasticsearch: Single, Multiple, Clear, and All">How to Delete Data in Elasticsearch: Single, Multiple, Clear, and All</a><time datetime="2024-09-04T16:02:38.000Z" title="Created 2024-09-05 00:02:38">2024-09-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>