<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>探究Apache Flink支持的三种流处理场景 | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="keywords" content="Java,JVM,Spring,Spring Boot,Flink,Hadoop,Yarn,MySQL,Elasticsearch,Python,Kafka,Maven,Hbase,Kibana,Logstash,Tutorial,Technical Blogs,Data Structures,Algorithms,C,SQL,Data Science,Web Development,System Design,Interview Experience,Interview Preparation,Programming,Competitive Programming,Coding Contests,HTML,CSS,Computer Science,Programming Examples,Mathematics"><meta name="description" content="Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实">
<meta property="og:type" content="article">
<meta property="og:title" content="探究Apache Flink支持的三种流处理场景">
<meta property="og:url" content="http://linjiangxiong.com/2023/09/01/apache-flink-use-cases/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/2023/20230901-image1.png">
<meta property="article:published_time" content="2023-08-31T16:11:03.000Z">
<meta property="article:modified_time" content="2023-09-04T15:24:54.493Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/2023/20230901-image1.png"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2023/09/01/apache-flink-use-cases/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '探究Apache Flink支持的三种流处理场景',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-04 23:24:54'
}</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">探究Apache Flink支持的三种流处理场景</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">探究Apache Flink支持的三种流处理场景</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-08-31T16:11:03.000Z" title="Created 2023-09-01 00:11:03">2023-09-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-09-04T15:24:54.493Z" title="Updated 2023-09-04 23:24:54">2023-09-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><p>Apache Flink 是一个集众多具有竞争力的特性于一身的流处理引擎，是开发和运行多种不同类型应用程序的绝佳选择。Flink 提供了流处理和批处理支持、复杂的状态管理、事件时间处理语义以及状态的精确一次一致性保证等功能。此外，Flink 可以在多种资源管理框架上部署，比如 YARN 和 Kubernetes，也可以作为独立集群部署在裸机硬件上。Flink 的高可用配置确保了系统没有单点故障。实际上，Flink 能够扩展到数千个内核和 TB 级的应用状态，提供高吞吐量和低延迟，并为世界上一些要求最苛刻的流处理应用提供支持。</p>
<p>本文将介绍 Flink 支持的三类常见的有状态的流处理应用，分别为事件驱动型应用、数据管道应用和数据分析应用。</p>
<blockquote>
<p>注：这里为了突出有状态的流处理的用途之多，将不同应用的类别区分地很明显，而事实上大多数真实应用都会同时具有多种类别的特性。</p>
</blockquote>
<h2 id="事件驱动型应用"><a href="#事件驱动型应用" class="headerlink" title="事件驱动型应用"></a>事件驱动型应用</h2><p>第一种应用类型是事件驱动型应用。事件驱动型应用程序是有状态的应用程序，它从一个或多个事件流中摄取事件，并通过触发计算、状态更新或执行外部操作来响应这些事件。事件驱动型应用本质上是传统应用程序的演变。传统的应用程序将计算层和数据存储层分离，在这种架构中，应用程序从远程事务数据库读取数据并将其持久化。</p>
<p>相比之下，事件驱动型应用程序是基于有状态的流处理应用的设计。在这种架构中，数据和计算存储在同一位置，因此可以进行本地（内存或磁盘）数据访问。容错性通过定期将检查点（checkpoint）写入远程持久化存储来实现。下图展示了传统应用程序架构和事件驱动型应用程序之间的区别。</p>
<p><img src="/image/2023/20230901-image1.png" alt="image.png"><br>事件驱动型应用程序有很多优势。它们不需要查询远程数据库，而是通过本地访问数据来获得更好的性能，不论是在吞吐量还是延迟方面。检查点对常规事件处理的影响非常小，因为它们是异步和增量方式进行的。此外，在传统分层架构中，多个应用程序共享同一个数据库是很常见的。所以，当数据库发生变化时，例如因应用程序更新或服务扩展而改变了数据布局，传统的应用程序都需要进行谨慎协调。反观事件驱动型应用，由于只需考虑自身数据，因此在更改数据表示或服务扩容时所需的协调工作将大大减少。</p>
<p>那么，Flink 如何支持事件驱动型应用程序呢？事件驱动型应用程序的能力取决于流处理引擎处理时间和状态的能力。Flink 提供了许多出色的功能来支持这些概念。它提供了一套丰富的状态操作原语，允许以精确一次的一致性语义合并海量规模（TB 级别）的状态数据。此外，Flink 支持事件时间处理、高度可定制的窗口逻辑以及 ProcessFunction 提供的对时间的细粒度控制，使得实现高级业务逻辑成为可能。另外，Flink 还提供了一个复杂事件处理（CEP）库。</p>
<p>不过，Flink 在支持事件驱动型应用程序方面的一个重要功能是保存点（savepoint）。保存点是一个一致性的状态快照，可以用来初始化任意状态兼容的应用。通过保存点，可以放心地对应用进行升级或扩容/缩容，还可以启动多个版本的应用程序来进行 A/B 测试。</p>
<p>典型的事件驱动型应用程序包括欺诈检测、异常检测、基于规则的警报、业务流程监控和网络应用（如社交网络）等。</p>
<h2 id="数据分析应用"><a href="#数据分析应用" class="headerlink" title="数据分析应用"></a>数据分析应用</h2><p>第二种应用类型是数据分析应用。数据分析应用是指从原始数据中提取信息和洞察力的分析工作。传统的分析方式是在记录事件的有界数据集上进行批量查询或构建应用程序的形式进行的。为了得到最新数据的分析结果，必须先将最新数据添加到原来的分析数据集中，并重新执行查询或运行应用程序。分析结果会写入存储系统或作为报告发布。</p>
<p>借助先进的流处理引擎，我们可以实时地进行数据分析。流式查询或应用程序不再读取有界的数据集，而是接收实时的事件流，并在处理事件时不断生成和更新结果。结果可能写入外部数据库，也可以保存为内部状态。仪表盘应用程序可以从外部数据库读取最新结果，或直接查询应用程序的内部状态。</p>
<p>Apache Flink 支持流式和批量数据分析应用，如下图所示。</p>
<p><img src="/image/2023/20230901-image2.png" alt="image.png"></p>
<p>与批量分析相比，流式分析应用有许多优势。首先，流式分析消除了周期性导入和查询执行所带来的延迟，能够实现更低的延迟。其次，与批量查询相比，流式查询不需要处理输入数据中的人为边界，这些边界是由周期性导入和有界输入造成的。</p>
<p>流式分析的另一个优势是简化的应用架构。批量分析管道通常包含多个独立组件，需要定期调度数据摄取和查询执行。可靠地运行此类管道并不容易，因为一旦出现故障，会影响后续步骤的执行。相比之下，在先进的流处理器（如 Flink）上运行的流式分析应用程序包含从数据摄取到连续结果计算的所有步骤。因此，它可以依赖底层引擎提供的故障恢复机制。</p>
<p>Flink 如何支持数据分析类应用？Flink 为持续流式分析和批量分析都提供了全面的支持。具体而言，它内置了一个符合 ANSI 标准的 SQL 接口，将批、流查询的语义统一起来。无论是在记录事件的静态数据集上还是实时事件流上，相同 SQL 查询都会得到一致的结果。同时，Flink 还支持丰富的用户自定义函数，允许在 SQL 中执行自定义代码。如果还需进一步自定义逻辑，Flink 的 DataStream API 和 DataSet API 可以提供更多底层控制。</p>
<p>典型的数据分析应用包括电信网络质量监控、移动应用中的产品更新分析及实验评估、消费者技术中的实时数据即时分析和大规模图分析等。</p>
<h2 id="数据管道应用"><a href="#数据管道应用" class="headerlink" title="数据管道应用"></a>数据管道应用</h2><p>第三种应用类型是数据管道应用。我们知道，提取-转换-加载（ETL，Extract-Transform-Load）是在存储系统之间进行数据转换和数据迁移的常用方法。ETL 作业通常会定期性地触发，将数据从事务型数据库系统拷贝到分析型数据库或数据仓库。</p>
<p>数据管道的作用与 ETL 作业类似。它们可以转换和丰富数据，并将数据从一个存储系统移动到另一个存储系统。不过，它们以持续流模式运行，而不是定期触发。因此，它们能够从持续产生数据的源中读取记录，并以较低的延迟将其移动到目的地。例如，数据管道可以监控文件系统目录中的新文件，并将其数据写入事件日志。另一个应用可能会将事件流物化到数据库中，或者增量构建和优化查询索引。</p>
<p>下图描述了定期 ETL 作业和持续数据管道之间的区别。</p>
<p><img src="/image/2023/20230901-image3.png" alt="image.png"></p>
<p>与周期性 ETL 作业相比，持续数据管道的明显优势在于减少了将数据传输到目的地的延迟。此外，数据管道的用途更广，支持的用例更多，因为它们能够持续消费和发送数据。</p>
<p>那 Flink 是如何支持数据管道应用呢？Flink 的 SQL 接口（或 Table API）及其对用户自定义函数的支持可以解决许多常见的数据转换或丰富任务。具有更高级要求的数据管道可通过使用更通用的 DataStream API 来实现。Flink 为 Kafka、Kinesis、Elasticsearch 和 JDBC 数据库系统等各种存储系统提供了丰富的连接器。同时，它还提供了文件系统的连续型数据源及数据汇，可用来监控目录变化和以时间分区的方式写入文件。</p>
<p>典型的数据管道应用包括电子商务中的实时搜索索引构建和电子商务中的持续 ETL。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Flink 作为流行的开源流处理框架，支持三类常见的有状态的流处理应用，包括事件驱动型应用、数据管道应用和数据分析应用。通过使用 Flink，可以高效地处理有状态的数据流，实现各种复杂的实时数据处理任务。</p>
<p>（END）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2023/09/01/apache-flink-use-cases/">http://linjiangxiong.com/2023/09/01/apache-flink-use-cases/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a></div><div class="post-share"><div class="social-share" data-image="/image/2023/20230901-image1.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2023/09/02/apache-flink-performance-high-throughput-low-latency/" title="探索流式应用的性能指标：延迟和吞吐量解析"><img class="cover" src="/image/brand/flink-header-logo.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">探索流式应用的性能指标：延迟和吞吐量解析</div></div><div class="info-2"><div class="info-item-1">批处理应用和流式应用在性能需求上有所区别。对于批处理应用而言，我们通常关心作业的总执行时间，即从处理引擎读取输入、执行计算、写回结果所需的时间。但在数据流处理中，由于流式应用会持续执行且输入可能是无限的，所以没有总执行时间的概念。相反，流式应用需要尽可能快地计算结果，并能处理高速的事件接入。因此，我们用延迟和吞吐来表示这两方面的性能需求。 延迟延迟是指处理一个事件所需的时间，从接收事件到在输出中观察到事件处理效果的时间间隔。为了更直观地理解延迟，我们可以以去咖啡店喝咖啡为例。当你进门时，可能已经有其他顾客在里面了，需要排队等候。收银员收到你的付款后，将订单交给咖啡师准备饮品。饮品制作完成后，咖啡师会叫你的名字，你才能从吧台取走咖啡。在这个过程中，你在店内买咖啡的时间就是服务延迟，即从进门到喝到第一口咖啡的时间。 在流处理中，我们用时间片（如毫秒）来测量延迟。根据应用的不同，我们可能关注平均延迟、最大延迟或特定百分位数的延迟。例如，平均延迟为 10 毫秒表示平均每条数据在 10 毫秒内处理完毕，而第 95 百分位延迟在 10 毫秒内处理完毕意味着 95% 的事件都在 10...</div></div></div></a><a class="pagination-related" href="/2023/08/31/never-waste-a-midlife-crisis/" title="不要浪费你的中年危机"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">不要浪费你的中年危机</div></div><div class="info-2"><div class="info-item-1">我上个月刚满40岁，花了三周时间阅读《堂吉诃德》，因此中年危机一直在我的脑海中挥之不去。 “千万不要浪费你的中年危机。” 这是我在收听播客采访《威廉・布莱克与世界》（William Blake vs. The World）的作者约翰・希格斯（John Higgs）时听到的建议。(2022年我最喜欢的读物之一）。 希格斯说，他钦佩的艺术家都是像大卫・林奇（David Lynch）这样的人，“你不会觉得他们在这个世界上有什么明显的位置，但他们就是不顾一切地做自己的事情，于是一个位置就在他们周围建立起来了”。 他继续说道： “生态学中有一个概念叫‘生态位创造’（niche...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2022/10/18/lightweight-asynchronous-snapshots-for-distributed-dataflows/" title="Lightweight Asynchronous Snapshots for Distributed Dataflows"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-18</div><div class="info-item-2">Lightweight Asynchronous Snapshots for Distributed Dataflows</div></div><div class="info-2"><div class="info-item-1">Author皇家理工学院 Paris Carbone1 Gyula Fora ´2 Stephan Ewen3 Seif Haridi1,2 Kostas Tzoumas31KTH Royal Institute of Technology - {parisc,haridi}@kth.se2Swedish Institute of Computer Science - {gyfora, seif}@sics.se3Data Artisans GmbH - {stephan, kostas}@data-artisans.com AbstractDistributed stateful stream processing enables the deployment and execution of large scale continuous omputations in the cloud, targeting both low latency and high throughput. One of the most fundamental challenges of this...</div></div></div></a><a class="pagination-related" href="/2023/09/09/apache-flink-features/" title="Apache Flink的核心特性"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="info-item-2">Apache Flink的核心特性</div></div><div class="info-2"><div class="info-item-1">在大数据和实时数据处理的时代，Apache Flink 以其卓越的性能和灵活性成为了业界的明星。本文将深入探讨这款框架的核心特性，以帮助我们更好地理解其在大数据分析和实时数据处理方面的优势和应用场景。 批流一体Flink 采用了统一的流处理架构，可以用相同的编程模型和运行时系统支持有界数据的批处理和无界数据的实时流处理。这种设计理念使 Flink 在企业技术选型中具有重要意义： 首先，Flink 消除了批处理和流处理之间的鸿沟，企业无需再采用多套框架分别实现两者。这简化了架构设计，降低了系统复杂度。其次，统一的编程模型可以重用批处理和流处理的代码逻辑，提高开发效率。开发人员无需学习多种编程模型，大大减少了学习和开发成本。最后，单一的运行时系统简化了运维工作，无须部署和维护多套框架，可以节省大量运维成本。 也就是说，Flink 的统一流处理架构为企业提供了一个高效、灵活、易于使用的大数据处理解决方案。如果 Flink 能够满足业务需求，就无须用两种甚至多种框架分别实现批处理和流处理，这大大降低了架构设计、开发、运维的复杂度，可以节省大量人力成本。这是 Flink...</div></div></div></a><a class="pagination-related" href="/2023/03/10/lsm-tree-intro/" title="Flink Table Store文件存储结构——LSM树"><img class="cover" src="/image/2023/20230310.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="info-item-2">Flink Table Store文件存储结构——LSM树</div></div><div class="info-2"><div class="info-item-1">本文简要介绍了 Flink Table Store 底层文件存储的数据结构——LSM 树的相关概念。  LSM 树，亦称日志结构合并树，英文为 log-structured merge-tree。  Sorted Runs如下图所示，LSM 树将文件组织成若干个 Sorted Run，一个 Sorted Run 由一个或多个数据文件组成，每个数据文件只会隶属一个 Sorted Run。数据文件中的记录按主键排序，在一个 Sorted Run 中，数据文件的主键范围不会有重叠的情况。但在不同的 Sorted Run 中主键范围有可能会重叠，甚至是包含相同的主键。  当查询 LSM 树时，必须先合并所有的 Sorted Run，根据用户指定的合并引擎和每条记录的时间戳合并具有相同主键的所有记录。而新的记录在写到 LSM 树之前会先缓存在内存中，当内存缓冲区满时，内存中的所有记录会先进行排序，然后再刷到磁盘上，此时就创建了一个新的 Sorted Run。 Compaction随着越来越多的记录写入 LSM 树，Sorted Run 的数量也会越来越多。因为查询 LSM...</div></div></div></a><a class="pagination-related" href="/2023/02/16/flink-sql-table-api-configuration-dependency/" title="Flink依赖配置：Table API &amp; SQL"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-16</div><div class="info-item-2">Flink依赖配置：Table API &amp; SQL</div></div><div class="info-2"><div class="info-item-1">我是 Flink 初学者，现在我要在 Flink 应用程序中添加支持使用 Flink SQL 进行数据统计的功能，但我不知道应该添加哪些依赖。 程序使用 Java 语言开发，Flink 版本是当前最新的 1.16.1 版本，程序的功能是使用 Flink SQL 从 Kafka 读取数据，并把读取到数据直接进行标准输出。Kafka 的数据为 Canal 程序采集 MySQL 的 Binlog 日志，所以这里我使用到的 Table API 连接器有 Kafka Connector，Canal Connector。 pom.xml...</div></div></div></a><a class="pagination-related" href="/2023/09/10/apache-flink-history-server/" title="了解Flink中的History Server：记录和展示作业历史信息的重要工具"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="info-item-2">了解Flink中的History Server：记录和展示作业历史信息的重要工具</div></div><div class="info-2"><div class="info-item-1">Flink 中的 History Server 是一个非常有用的组件，可以在相应的 Flink 集群关闭之后查询已完成作业的统计信息。并且，它还提供了一个 REST API，可接受 HTTP 请求并以 JSON 数据作为响应。本文将详细介绍 Flink History Server 的工作原理和主要功能。 一、History Server工作原理Apache Flink 自带了一个 HistoryServer 进程，它是一个独立的 Web 服务器。HistoryServer 不参与 Flink 作业执行，仅用于展示作业的历史信息。它的工作原理如下：  JobManager 会将已完成的作业的信息以存档文件的形式写入 HDFS 或者其他持久存储中。 HistoryServer 读取这些存档文件，并提供 Web 界面展示其信息内容。 用户通过 HistoryServer 的 Web UI 查看作业记录和运行数据。  每个作业完成后，JobManager 会把该作业的信息打包成一个个 JSON 格式的归档文件，包括作业配置信息、作业执行过程中的 Checkpoint...</div></div></div></a><a class="pagination-related" href="/2023/09/02/apache-flink-performance-high-throughput-low-latency/" title="探索流式应用的性能指标：延迟和吞吐量解析"><img class="cover" src="/image/brand/flink-header-logo.svg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-02</div><div class="info-item-2">探索流式应用的性能指标：延迟和吞吐量解析</div></div><div class="info-2"><div class="info-item-1">批处理应用和流式应用在性能需求上有所区别。对于批处理应用而言，我们通常关心作业的总执行时间，即从处理引擎读取输入、执行计算、写回结果所需的时间。但在数据流处理中，由于流式应用会持续执行且输入可能是无限的，所以没有总执行时间的概念。相反，流式应用需要尽可能快地计算结果，并能处理高速的事件接入。因此，我们用延迟和吞吐来表示这两方面的性能需求。 延迟延迟是指处理一个事件所需的时间，从接收事件到在输出中观察到事件处理效果的时间间隔。为了更直观地理解延迟，我们可以以去咖啡店喝咖啡为例。当你进门时，可能已经有其他顾客在里面了，需要排队等候。收银员收到你的付款后，将订单交给咖啡师准备饮品。饮品制作完成后，咖啡师会叫你的名字，你才能从吧台取走咖啡。在这个过程中，你在店内买咖啡的时间就是服务延迟，即从进门到喝到第一口咖啡的时间。 在流处理中，我们用时间片（如毫秒）来测量延迟。根据应用的不同，我们可能关注平均延迟、最大延迟或特定百分位数的延迟。例如，平均延迟为 10 毫秒表示平均每条数据在 10 毫秒内处理完毕，而第 95 百分位延迟在 10 毫秒内处理完毕意味着 95% 的事件都在 10...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">305</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">55</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E5%9E%8B%E5%BA%94%E7%94%A8"><span class="toc-number">1.</span> <span class="toc-text">事件驱动型应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BA%94%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">数据分析应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93%E5%BA%94%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">数据管道应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">小结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/29/multiple-jobs-or-multiple-pipelines-in-one-job-in-flink/" title="Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines">Running Multiple Pipelines in Apache Flink: Separate Jobs vs. Single Job with Multiple Pipelines</a><time datetime="2024-10-28T23:10:18.000Z" title="Created 2024-10-29 07:10:18">2024-10-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/18/bulk-deleting-keys-in-redis-using-wildcards/" title="Bulk Deleting Keys in Redis Using Wildcards">Bulk Deleting Keys in Redis Using Wildcards</a><time datetime="2024-09-18T15:42:56.000Z" title="Created 2024-09-18 23:42:56">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"><img src="/image/redis-src/2024091101.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing"/></a><div class="content"><a class="title" href="/2024/09/11/analyzing-redis-source-code-hash/" title="Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing">Analyzing Redis Source Code: The Structure and Design of Hash Tables, Chained Hashing, and Incremental Rehashing</a><time datetime="2024-09-10T22:28:03.000Z" title="Created 2024-09-11 06:28:03">2024-09-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"><img src="/image/redis-src/24091002.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation"/></a><div class="content"><a class="title" href="/2024/09/10/analyzing-redis-source-code-sds/" title="Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation">Analyzing Redis Source Code: Simple Dynamic Strings (SDS) – An Efficient and Flexible String Implementation</a><time datetime="2024-09-09T17:13:55.000Z" title="Created 2024-09-10 01:13:55">2024-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/06/why-does-redis-use-the-sds-structure-for-strings-instead-of-char/" title="Why Does Redis Use the SDS Structure for Strings Instead of char*?">Why Does Redis Use the SDS Structure for Strings Instead of char*?</a><time datetime="2024-09-05T16:01:26.000Z" title="Created 2024-09-06 00:01:26">2024-09-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>