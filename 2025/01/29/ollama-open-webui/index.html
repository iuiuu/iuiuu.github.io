<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Ollama Open WebUI | Johnson Lin</title><meta name="author" content="Johnson Lin"><meta name="copyright" content="Johnson Lin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Open WebUI is a user-friendly AI interface that supports Ollama, OpenAI API, and more.   It’s a powerful AI deployment solution that works with multiple language model runners (like Ollama and OpenAI-">
<meta property="og:type" content="article">
<meta property="og:title" content="Ollama Open WebUI">
<meta property="og:url" content="http://linjiangxiong.com/2025/01/29/ollama-open-webui/index.html">
<meta property="og:site_name" content="Johnson Lin">
<meta property="og:description" content="Open WebUI is a user-friendly AI interface that supports Ollama, OpenAI API, and more.   It’s a powerful AI deployment solution that works with multiple language model runners (like Ollama and OpenAI-">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://linjiangxiong.com/image/IMG_3665.JPG">
<meta property="article:published_time" content="2025-01-29T11:20:42.000Z">
<meta property="article:modified_time" content="2025-02-17T22:45:14.319Z">
<meta property="article:author" content="Johnson Lin">
<meta property="article:tag" content="Ollama">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://linjiangxiong.com/image/IMG_3665.JPG"><link rel="shortcut icon" href="/image/IMG_3665.JPG"><link rel="canonical" href="http://linjiangxiong.com/2025/01/29/ollama-open-webui/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&amp;family=Source+Sans+3:wght@400;600&amp;display=swap"><link rel="stylesheet" href="/css/ud_v5.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca45da0012a3ce293c6ca4f7e5ebc3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'WLKqFH01ST8bHfxLtjsterJZnoEpVlF26sn-Nzzoqfc', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ollama Open WebUI',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/IMG_3665.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">492</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">65</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2025/01/29/ollama-tutorial/"><i class="fa-fw fas fa-book"></i><span> Ollama Tutorial</span></a></li><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/2024/08/27/yaml-tutorial/"><i class="fa-fw fas fa-book"></i><span> YAML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><span> Dev Wiki</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/11/29/wiki/standard-ascii-table/"><i class="fa-fw fas fa-book"></i><span> Standard ASCII Table (7-bit)</span></a></li><li><a class="site-page child" href="/2025/01/17/a-complete-guide-to-base64-encoding-and-decoding/"><i class="fa-fw fas fa-book"></i><span> Base64 Introduction</span></a></li><li><a class="site-page child" href="/2024/11/30/wiki/html-char/"><i class="fa-fw fas fa-book"></i><span> HTML Special Char</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><span> Dev Tools</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tools/json-formatter/"><i class="fa-fw fas fa-link"></i><span> JSON Formatter</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Johnson Lin</span></a><a class="nav-page-title" href="/"><span class="site-name">Ollama Open WebUI</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> Instant Tutorials</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2025/01/29/ollama-tutorial/"><i class="fa-fw fas fa-book"></i><span> Ollama Tutorial</span></a></li><li><a class="site-page child" href="/2024/06/29/html-instant-tutorial/"><i class="fa-fw fas fa-book"></i><span> HTML Tutorial</span></a></li><li><a class="site-page child" href="/2024/08/27/yaml-tutorial/"><i class="fa-fw fas fa-book"></i><span> YAML Tutorial</span></a></li><li><a class="site-page child" href="/categories/Bash-Tutorial/"><i class="fa-fw fas fa-book"></i><span> Bash Tutorial</span></a></li><li><a class="site-page child" href="/2023/09/05/tutorial-gson/"><i class="fa-fw fas fa-music"></i><span> 极简教程 - Gson</span></a></li><li><a class="site-page child" href="/categories/Redis%E6%95%99%E7%A8%8B/"><i class="fa-fw fas fa-book"></i><span> Redis教程</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><span> Dev Wiki</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/2024/11/29/wiki/standard-ascii-table/"><i class="fa-fw fas fa-book"></i><span> Standard ASCII Table (7-bit)</span></a></li><li><a class="site-page child" href="/2025/01/17/a-complete-guide-to-base64-encoding-and-decoding/"><i class="fa-fw fas fa-book"></i><span> Base64 Introduction</span></a></li><li><a class="site-page child" href="/2024/11/30/wiki/html-char/"><i class="fa-fw fas fa-book"></i><span> HTML Special Char</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><span> Dev Tools</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tools/json-formatter/"><i class="fa-fw fas fa-link"></i><span> JSON Formatter</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Ollama Open WebUI</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-01-29T11:20:42.000Z" title="Created 2025-01-29 19:20:42">2025-01-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-02-17T22:45:14.319Z" title="Updated 2025-02-18 06:45:14">2025-02-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Ollama-Tutorial/">Ollama Tutorial</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>Open WebUI is a user-friendly AI interface that supports Ollama, OpenAI API, and more.  </p>
<p>It’s a powerful AI deployment solution that works with multiple language model runners (like Ollama and OpenAI-compatible APIs) and includes a built-in inference engine for Retrieval-Augmented Generation (RAG).  </p>
<p>With Open WebUI, you can customize the OpenAI API URL to connect to services like LMStudio, GroqCloud, Mistral, and OpenRouter.  </p>
<p>Administrators can create detailed user roles and permissions, ensuring a secure environment while offering a personalized user experience.  </p>
<p>Open WebUI is compatible with desktops, laptops, and mobile devices. It also supports Progressive Web Apps (PWA) for offline access on mobile.  </p>
<p><strong>Open Source Repository</strong>: <a target="_blank" rel="noopener" href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a><br><strong>Official Documentation</strong>: <a target="_blank" rel="noopener" href="https://docs.openwebui.com/">https://docs.openwebui.com/</a>  </p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a><strong>Installation</strong></h2><p>Open WebUI offers multiple installation options, including Python pip, Docker, Docker Compose, Kustomize, and Helm.  </p>
<h3 id="Quick-Start-with-Docker"><a href="#Quick-Start-with-Docker" class="headerlink" title="Quick Start with Docker"></a><strong>Quick Start with Docker</strong></h3><p>If Ollama is already installed on your system, use the following command:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure>
<p>For Nvidia GPU support:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda</span><br></pre></td></tr></table></figure>
<h3 id="Bundled-Installation-with-Ollama"><a href="#Bundled-Installation-with-Ollama" class="headerlink" title="Bundled Installation with Ollama"></a><strong>Bundled Installation with Ollama</strong></h3><p>This method combines Open WebUI and Ollama into a single container for easy setup.  </p>
<p>For GPU support:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama</span><br></pre></td></tr></table></figure>
<p>For CPU-only setups:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama</span><br></pre></td></tr></table></figure>
<p>Once installed, access Open WebUI at <a target="_blank" rel="noopener" href="http://localhost:3000">http://localhost:3000</a>.  </p>
<h3 id="Updating-Open-WebUI"><a href="#Updating-Open-WebUI" class="headerlink" title="Updating Open WebUI"></a><strong>Updating Open WebUI</strong></h3><h4 id="Manual-Update"><a href="#Manual-Update" class="headerlink" title="Manual Update"></a><strong>Manual Update</strong></h4><p>Use Watchtower to manually update the Docker container:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --<span class="built_in">rm</span> -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui</span><br></pre></td></tr></table></figure>
<h4 id="Automatic-Updates"><a href="#Automatic-Updates" class="headerlink" title="Automatic Updates"></a><strong>Automatic Updates</strong></h4><p>To update the container every 5 minutes:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name watchtower --restart unless-stopped -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --interval 300 open-webui</span><br></pre></td></tr></table></figure>
<p><em>Note</em>: Replace <code>open-webui</code> with your container name if it’s different.  </p>
<h3 id="Manual-Installation"><a href="#Manual-Installation" class="headerlink" title="Manual Installation"></a><strong>Manual Installation</strong></h3><p>Open WebUI can be installed using either the <code>uv</code> runtime manager or Python’s <code>pip</code>.  </p>
<h4 id="Using-uv-Recommended"><a href="#Using-uv-Recommended" class="headerlink" title="Using uv (Recommended)"></a><strong>Using </strong><code>uv</code><strong> (Recommended)</strong></h4><p><code>uv</code> simplifies environment management and reduces potential conflicts.  </p>
<p><strong>macOS/Linux</strong>:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br></pre></td></tr></table></figure>
<p><strong>Windows</strong>:  </p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">powershell <span class="literal">-ExecutionPolicy</span> ByPass <span class="literal">-c</span> <span class="string">&quot;irm https://astral.sh/uv/install.ps1 | iex&quot;</span></span><br></pre></td></tr></table></figure>
<p>After installing <code>uv</code>, run Open WebUI with the following commands. Make sure to set the <code>DATA_DIR</code> environment variable to avoid data loss.  </p>
<p><strong>macOS/Linux</strong>:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DATA_DIR=~/.open-webui uvx --python 3.11 open-webui@latest serve</span><br></pre></td></tr></table></figure>
<p><strong>Windows</strong>:  </p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$env:DATA_DIR</span>=<span class="string">&quot;C:\open-webui\data&quot;</span>; uvx <span class="literal">--python</span> <span class="number">3.11</span> <span class="built_in">open-webui</span>@latest serve</span><br></pre></td></tr></table></figure>
<h4 id="Using-pip"><a href="#Using-pip" class="headerlink" title="Using pip"></a><strong>Using </strong><code>pip</code></h4><p>Ensure you’re using Python 3.11 to avoid compatibility issues.  </p>
<p>Install Open WebUI with:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install open-webui</span><br></pre></td></tr></table></figure>
<p>Start the server with:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open-webui serve</span><br></pre></td></tr></table></figure>
<p>Once running, access Open WebUI at <a target="_blank" rel="noopener" href="http://localhost:8080">http://localhost:8080</a>.  </p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com">Johnson Lin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://linjiangxiong.com/2025/01/29/ollama-open-webui/">http://linjiangxiong.com/2025/01/29/ollama-open-webui/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Ollama/">Ollama</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/image/IMG_3665.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/01/29/ollama-python-sdk/" title="Using Ollama with Python"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Using Ollama with Python</div></div><div class="info-2"><div class="info-item-1">Ollama provides a Python SDK that allows you to interact with locally running models directly from your Python environment. This SDK makes it easy to integrate natural language processing tasks into your Python projects, enabling operations like text generation, conversational AI, and model management—all without the need for manual command-line interactions. Installing the Python SDKTo get started, you’ll need to install the Ollama Python SDK. You can do this using pip: 1pip install...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-page-assist/" title="Ollama Page Assist"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Ollama Page Assist</div></div><div class="info-2"><div class="info-item-1">Page Assist is an open-source browser extension that provides an intuitive interface for interacting with local AI models. It allows users to chat and engage with local AI models directly on any webpage.   Key Features Sidebar Interaction: Open a sidebar on any webpage to chat with your local AI model and get intelligent assistance related to the page content.   Web UI: A ChatGPT-like interface for more comprehensive conversations with the AI model.   Web Content Interaction: Chat directly...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/01/29/ollama-commands/" title="Ollama Commands Overview"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Ollama Commands Overview</div></div><div class="info-2"><div class="info-item-1">Ollama CommandsOllama offers a variety of command-line tools (CLI) for interacting with locally running models. To see a list of available commands, you can use: 1ollama --help This will display the following: 12345678910111213141516171819202122232425Large language model runnerUsage:  ollama [flags]  ollama [command]Available Commands:  serve       Start ollama  create      Create a model from a Modelfile  show        Show information for a model  run         Run a model  stop        Stop a...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-intro/" title="Introduction to Ollama"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Introduction to Ollama</div></div><div class="info-2"><div class="info-item-1">Ollama is an open-source platform for large language models (LLMs), designed to make it easy for users to run, manage, and interact with LLMs directly on their local machines.   It provides a straightforward way to load and use various pre-trained language models, supporting a wide range of natural language processing tasks such as text generation, translation, code writing, and question answering.   What sets Ollama apart is its combination of ready-to-use models and tools with...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-install/" title="Installing Ollama"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Installing Ollama</div></div><div class="info-2"><div class="info-item-1">Ollama supports multiple operating systems, including macOS, Windows, Linux, and Docker containers.   It has modest hardware requirements, making it easy for users to run, manage, and interact with large language models locally.   Hardware and Software Requirements CPU: A multi-core processor (4 cores or more recommended).   GPU: If you plan to run large models or perform fine-tuning, a GPU with high computational power (e.g., NVIDIA with CUDA support) is recommended.   RAM: At least 8GB of...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-tutorial/" title="Ollama Tutorial"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Ollama Tutorial</div></div><div class="info-2"><div class="info-item-1"> Ollama is an open-source framework designed to make it easy to deploy and run large language models (LLMs) directly on your local machine. It supports multiple operating systems, including macOS, Windows, Linux, and even Docker containers. One of its standout features is model quantization, which significantly reduces GPU memory requirements, making it possible to run large models on everyday home computers. Who Is This Tutorial For?Ollama is ideal for developers, researchers, and users...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-run-model/" title="Running Models with Ollama"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Running Models with Ollama</div></div><div class="info-2"><div class="info-item-1">To run a model in Ollama, use the ollama run command.   For example, to run the DeepSeek-R1:8b model and interact with it, use the following command:  1ollama run deepseek-r1:8b If the model isn’t already installed, Ollama will automatically download it.   Once the download is complete, you can interact with the model directly in the terminal:   1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950C:\Users\Administrator&gt;ollama run...</div></div></div></a><a class="pagination-related" href="/2025/01/29/ollama-core-concepts/" title="Ollama Core Concepts"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-29</div><div class="info-item-2">Ollama Core Concepts</div></div><div class="info-2"><div class="info-item-1">Ollama is a localized machine learning framework designed for various natural language processing (NLP) tasks. It focuses on model loading, inference, and generation, making it easy for users to interact with large pre-trained models deployed locally. ModelsModels are the heart of Ollama. These are pre-trained machine learning models capable of performing tasks like text generation, summarization, sentiment analysis, and dialogue generation. Ollama supports a wide range of popular...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/IMG_3665.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Johnson Lin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">492</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">65</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/iuiuu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/iuiuu" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:me@linjiangxiong.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Installation"><span class="toc-number">1.</span> <span class="toc-text">Installation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Quick-Start-with-Docker"><span class="toc-number">1.1.</span> <span class="toc-text">Quick Start with Docker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bundled-Installation-with-Ollama"><span class="toc-number">1.2.</span> <span class="toc-text">Bundled Installation with Ollama</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Updating-Open-WebUI"><span class="toc-number">1.3.</span> <span class="toc-text">Updating Open WebUI</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Manual-Update"><span class="toc-number">1.3.1.</span> <span class="toc-text">Manual Update</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Automatic-Updates"><span class="toc-number">1.3.2.</span> <span class="toc-text">Automatic Updates</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Manual-Installation"><span class="toc-number">1.4.</span> <span class="toc-text">Manual Installation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Using-uv-Recommended"><span class="toc-number">1.4.1.</span> <span class="toc-text">Using uv (Recommended)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Using-pip"><span class="toc-number">1.4.2.</span> <span class="toc-text">Using pip</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/14/ollama-tutorial/" title="Introduction to JSON Web Tokens (JWT)">Introduction to JSON Web Tokens (JWT)</a><time datetime="2025-02-13T18:08:18.000Z" title="Created 2025-02-14 02:08:18">2025-02-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/10/integrating-deepseek-into-vscode/" title="Integrating DeepSeek into VSCode: A Game-Changer for Developers">Integrating DeepSeek into VSCode: A Game-Changer for Developers</a><time datetime="2025-02-09T22:41:00.000Z" title="Created 2025-02-10 06:41:00">2025-02-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/06/how-to-run-deepseek-locally-on-windows/" title="How To Run DeepSeek Locally On Windows?">How To Run DeepSeek Locally On Windows?</a><time datetime="2025-02-05T18:27:11.000Z" title="Created 2025-02-06 02:27:11">2025-02-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/29/ollama-page-assist/" title="Ollama Page Assist">Ollama Page Assist</a><time datetime="2025-01-29T12:15:55.000Z" title="Created 2025-01-29 20:15:55">2025-01-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/29/ollama-open-webui/" title="Ollama Open WebUI">Ollama Open WebUI</a><time datetime="2025-01-29T11:20:42.000Z" title="Created 2025-01-29 19:20:42">2025-01-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Johnson Lin</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly/source/js/main.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>